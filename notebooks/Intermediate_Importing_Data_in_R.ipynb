{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["d6xTtnP_QTMI","joqd182UQ96a","XX4hx4IORXsY","MbhN81z_SxJP","MGyNJy4_TMH_","m6CctHWGYgY2","3Xb3t2JTcXwF","RbEP3A9qfM2J","UbBNx4RMgBzy","PE43qJ9sgvCB","2Ly3OX8Si6XB","10k-4B7Q73-r","9MSEkDOP8Oz8","6y2nNneQ9AzD","Fe0AVzvGAQdb","4gaWWV_JAs2A","5Te4oB0mBk-k","FHD2_ksKJ_xx","Kfh3jQ74KqtA","5iojxxLdLbao","P66vQbE7MNYI","zHp9WM3WO_f5","loEenVALQCaY","bwrF0SUtQac1","ps5R9aTyRITP","ki16YkHFR15v"],"authorship_tag":"ABX9TyP8GT6Pl/tU4hIKOa7tiEP4"},"kernelspec":{"name":"ir","display_name":"R"},"language_info":{"name":"R"}},"cells":[{"cell_type":"markdown","source":["+ https://rpubs.com/odenipinedo/intermediate-importing-data-in-R"],"metadata":{"id":"ctOsFnmbkozO"}},{"cell_type":"markdown","source":["###**Se connecter à une base de données**\n","\n","####**1. Se connecter à une base de données**\n","\n","+ Bienvenue dans la deuxième partie de l’importation de données dans R !\n","\n","####**2. Jusqu’à présent**\n","\n","+ Le cours précédent traitait de l’accès aux données stockées dans des fichiers plats ou des fichiers Excel. \n","+ Dans un cadre professionnel, vous rencontrerez également des données stockées dans des bases de données relationnelles.\n","\n","####**3. Bases de données relationnelles**\n","\n","+ Dans cette partie, je parlerai brièvement de ce qu’est une base de données relationnelle, puis j’expliquerai comment vous pouvez vous y connecter. \n","+ Dans la prochaine vidéo, je vous expliquerai comment vous pouvez importer des données à partir de celui-ci! \n","\n","+ Alors, qu’est-ce qu’une base de données relationnelle ? Il n’y a pas de meilleure façon de montrer cela qu’avec un exemple.\n","\n","####**4. Société**\n","+ Prenez cette base de données, appelée société. Il contient trois tableaux,\n","\n","####**5. Société**\n","salariés\n","\n","####**6. Société**\n","produits et\n","\n","####**7. Société**\n","\n","ventes. \n","\n","+ Comme un fichier plat, les informations sont affichées sous forme de tableau. \n","\n","+ La table employees comporte 5 enregistrements et trois champs, à savoir id, nom et started_at.\n","\n","+ L’id sert ici de clé unique pour chaque ligne ou enregistrement. \n","\n","+ Ensuite, le tableau des produits contient les détails sur quatre produits. \n","\n","+ Nous traitons des données provenant d’une entreprise de télécommunications qui vend à la fois avec et sans contrat. \n","\n","+ Ici aussi, chaque produit a un identifiant. Enfin, il y a la table des ventes. \n","\n","+ Il énumère quels produits ont été vendus par qui, quand et à quel prix. Notez ici que les identifiants dans\n","\n","####**8. Société**\n","employee_id et\n","\n","####**9. Société**\n","product_id correspondent aux ID que vous pouvez trouver respectivement dans le tableau des employés et des produits.\n","\n","####**10. Société**\n","\n","+ La troisième vente, par exemple, a été faite par l’employé avec id 6, donc Julie. Elle a vendu le produit avec id 9, donc le contrat Biz Unlimited.\n","\n","####**11. Société**\n","\n","+ Ces relations rendent cette base de données très puissante. \n","\n","+ Vous ne stockez toutes les informations nécessaires qu’une seule fois dans des tableaux bien séparés, mais vous pouvez relier les points entre différents enregistrements pour modéliser ce qui se passe.\n","\n","####**12. Système de gestion de base de données**\n","\n","+ La façon dont les données d’une base de données relationnelle sont stockées et mélangées lorsque vous effectuez des adaptations dépend du système de gestion de base de données, ou SGBD que vous utilisez. \n","\n","+ Les implémentations open-source telles que **MySQL, postgreSQL et SQLite sont très populaires, mais il existe également des implémentations propriétaires telles que Oracle Database et Microsoft SQL Server**. \n","\n","+ Pratiquement toutes ces implémentations utilisent SQL, ou suite, comme langage d’interrogation et de maintenance de la base de données. \n","\n","+ SQL signifie Structured Query Language (langage de requête structuré).\n","\n","####**13. Bases de données dans R**\n","\n","+ Selon le type de base de données auquel vous souhaitez vous connecter, vous devrez utiliser différents packages. \n","\n","+ Supposons que la base de données d’entreprise que j’ai introduite auparavant soit une base de données MySQL. \n","+ Cela signifie que vous aurez besoin du package RMySQL. \n","\n","+ Pour postgreSQL, vous aurez besoin de RpostgreSQL, pour Oracle, vous utiliserez ROracle et ainsi de suite. \n","\n","+ La façon dont vous interagissez avec la base de données, c’est-à-dire les fonctions R que vous utilisez pour accéder à la base de données et la manipuler, est spécifiée dans un autre package R appelé DBI. \n","\n","+ En termes plus techniques, DBI est une interface, et RMySQL est l’implémentation. \n","\n","+ Installons le package RMySQL, qui installe également automatiquement le package DBI. \n","\n","+ Le chargement uniquement du package DBI suffira pour commencer.\n","\n","####**14. Se connecter à la base de données**\n","\n","+ La première étape consiste à créer une connexion à la base de données MySQL distante. \n","\n","+ Pour ce faire, utilisez dbConnect, comme suit. \n","\n","+ Le premier argument spécifie le pilote que vous utiliserez pour vous connecter à la base de données MySQL. \n","\n","+ Cela semble un peu étrange, mais la fonction MySQL du package RMySQL construit simplement un pilote pour nous que dbConnect peut utiliser. \n","\n","+ Ensuite, vous devez spécifier le nom de la base de données, où la base de données est hébergée, par quel port vous souhaitez vous connecter, et enfin les informations d’identification pour vous authentifier. \n","\n","+ Il s’agit d’une base de données réelle que nous hébergeons, vous pouvez donc essayer ces commandes vous-même! Le résultat de l’appel dbConnect, con, est un objet de connexion DBI. \n","\n","+ Vous devrez passer cet objet à la fonction que vous utilisez pour interagir avec la base de données.\n","\n","####**15. Entraînons-nous!**\n","+ Avant de faire cela, familiarisons-nous avec cet objet de connexion dans les exercices!"],"metadata":{"id":"c2HrzzNXG3Xf"}},{"cell_type":"markdown","source":["###**EXERCICES**\n","\n","####**Établir une connexion**\n","\n","+ La première étape pour importer des données d'une base de données SQL est de créer une connexion à celle-ci. \n","\n","+ Comme l'a expliqué Filip, vous avez besoin de différents packages en fonction de la base de données à laquelle vous souhaitez vous connecter. \n","\n","+ Tous ces paquets le font de manière uniforme, comme spécifié dans le paquet DBI.\n","\n","+ **dbConnect()** crée une connexion entre votre session R et une base de données SQL. \n","\n","+ Le premier argument doit être un objet DBIdriver, qui spécifie comment les connexions sont établies et comment les données sont mappées entre R et la base de données. \n","\n","+ Spécifiquement pour les bases de données MySQL, vous pouvez construire un tel pilote avec **RMySQL::MySQL()**.\n","\n","+ **Si la base de données MySQL** est une base de données distante hébergée sur un serveur, vous devrez également spécifier les arguments suivants dans dbConnect() : **dbname, hôte, port, utilisateur et mot de passe**. \n","+ La plupart de ces détails ont déjà été fournis.\n","\n","####**Instructions**\n","\n","+ Chargez la bibliothèque DBI, qui est déjà installée sur les serveurs de DataCamp.\n","\n","+ Modifiez l'appel dbConnect() pour vous connecter à la base de données MySQL. \n","\n","+ Changez l'argument port (3306) et l'argument utilisateur (\"student\")"],"metadata":{"id":"KgvX4kV6JTsu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sCOThJdaFiG-"},"outputs":[],"source":["# Load the DBI package\n","library(DBI)\n","\n","# Edit dbConnect() call\n","con <- dbConnect(RMySQL::MySQL(), \n","                 dbname = \"tweater\", \n","                 host = \"courses.csrrinzqubik.us-east-1.rds.amazonaws.com\", \n","                 port = 3306,\n","                 user = \"student\",\n","                 password = \"datacamp\")\n","con"]},{"cell_type":"markdown","source":["####**Inspecter la connexion**\n","\n","+ Maintenant que vous avez réussi à créer la connexion à la base de données, examinons-la de plus près. \n","+ Avec l'objet con disponible dans votre espace de travail, pouvez-vous dire laquelle des affirmations suivantes est vraie ?\n","\n","####**Instructions**\n","\n","\n","+ con est un objet SQLConnection.\n","\n","+ con est un objet PostgreSQLConnection.\n","\n","+ **con est un objet MySQLConnection.**\n","\n","+ con est un objet NoSQLConnection."],"metadata":{"id":"ZOBunA5eKZXW"}},{"cell_type":"markdown","source":["###**Importer les données de table**\n","\n","####**1. Importer les données de table**\n","+ Après s’être connecté avec succès à une base de données,\n","\n","####**2. Contre**\n","+ Comme ça, vous voudrez probablement voir ce qu’il y a dedans.\n","\n","####**3. Lister et importer des tables**\n","\n","+ La première étape consiste à répertorier toutes les tables de la base de données. \n","\n","+ Vous pouvez le faire avec la fonction **dbListTables**. Il suffit de passer la variable **con**. \n","\n","+ Comme prévu, nous obtenons un vecteur de caractères de longueur trois, correspondant aux noms de table que j’ai introduits précédemment. \n","\n","+ Ensuite, vous pouvez choisir de lire les données de l’une de ces tables, par exemple de la table employees. \n","\n","+ Vous utilisez la fonction dbReadTable pour cela. \n","\n","+ Encore une fois, vous spécifiez la connexion à utiliser, con, mais cette fois, vous spécifiez également les données de table que vous souhaitez importer : \n","  + Le résultat est une trame de données, avec exactement le même contenu que dans la table de base de données d’origine. \n","  \n","+ **DBI** spécifie également des fonctions pour créer de nouvelles tables, stocker de nouvelles données dans des tables et supprimer des tables, mais ce n’est pas vraiment lié à l’importation de données, donc je n’en parlerai pas ici. \n","\n","+ Les fonctions que nous avons couvertes jusqu’à présent fournissent déjà un assez bon point de départ. \n","\n","+ Oh non, attendez, il y a une dernière chose! Il est toujours poli de déconnecter explicitement votre base de données une fois que vous avez terminé. \n","\n","+ Pour ce faire, utilisez dbDisconnect, comme suit. Si vous essayez maintenant d’imprimer con, vous verrez qu’il n’est plus disponible. Bon débarras\n","\n","####**4. Entraînons-nous!**\n","+ C’est parti pour les exercices maintenant!"],"metadata":{"id":"Gz8Za5d6Kpp5"}},{"cell_type":"markdown","source":["####**Lister les tables de la base de données**\n","\n","+ Une fois que vous avez réussi à vous connecter à une base de données MySQL distante, l'étape suivante consiste à voir quelles tables la base de données contient. \n","\n","+ Vous pouvez le faire avec la fonction **dbListTables()**. \n","\n","+ Comme vous vous en souvenez peut-être dans la partie ci-dessus, cette fonction requiert l'objet de connexion en entrée et produit un vecteur de caractères contenant les noms des tables.\n","\n","####**Instructions**\n","\n","+ Ajoutez du code pour créer un vecteur tables, qui contient les tables dans la base de données tweater. \n","\n","+ Vous pouvez vous connecter à cette base de données par l'objet con.\n","\n","+ Affichez la structure des tables ; quelle est la classe de ce vecteur ?"],"metadata":{"id":"YcqdyqCzLzTl"}},{"cell_type":"code","source":["# Load the DBI package\n","library(DBI)\n","\n","# Connect to the MySQL database: con\n","con <- dbConnect(RMySQL::MySQL(), \n","                 dbname = \"tweater\", \n","                 host = \"courses.csrrinzqubik.us-east-1.rds.amazonaws.com\", \n","                 port = 3306,\n","                 user = \"student\",\n","                 password = \"datacamp\")\n","\n","# Build a vector of table names: tables\n","tables <- dbListTables(con)\n","\n","# Display structure of tables\n","str(tables)"],"metadata":{"id":"FA4StE4DKjKc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Utilisateurs de mport**\n","\n","+ Comme vous l'avez peut-être déjà deviné, la base de données contient des données sur une version plus savoureuse de Twitter, à savoir Tweater. \n","\n","+ Les utilisateurs peuvent publier des tweets contenant de courtes recettes de délicieux en-cas. \n","\n","+ Les gens peuvent commenter ces tweats. \n","\n","+ Il y a trois tables : **utilisateurs, tweats, et commentaires** qui ont des relations entre eux. \n","\n","+ Lesquelles, demandez-vous ? Vous allez le découvrir dans un instant !\n","\n","+ Commençons par importer les données sur les utilisateurs dans votre session R. \n","\n","+ Pour ce faire, utilisez la fonction **dbReport**. \n","\n","+ Pour ce faire, utilisez la fonction **dbReadTable()**. \n","\n","+ Il suffit de lui passer l'objet de connexion (con), suivi du nom de la table que vous souhaitez importer. L'objet résultant est un cadre de données R standard.\n","\n","####**Instructions**\n","\n","+ Ajoutez le code qui importe la table \"users\" de la base de données tweater et stockez le cadre de données résultant en tant que users.\n","\n","+ Imprimez le cadre de données users."],"metadata":{"id":"J4YYcnUIMkrk"}},{"cell_type":"code","source":["# Load the DBI package\n","library(DBI)\n","\n","# Connect to the MySQL database: con\n","con <- dbConnect(RMySQL::MySQL(), \n","                 dbname = \"tweater\", \n","                 host = \"courses.csrrinzqubik.us-east-1.rds.amazonaws.com\", \n","                 port = 3306,\n","                 user = \"student\",\n","                 password = \"datacamp\")\n","\n","# Import the users table from tweater: users\n","users <- dbReadTable(con, \"users\")\n","\n","# Print users\n","users"],"metadata":{"id":"mhlSejrVM4dj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Importer toutes les tables**\n","\n","+ En plus des utilisateurs, nous sommes également intéressés par les tables tweats et commentaires. \n","\n","+ Cependant, des appels **dbReadTable()** distincts pour chacune des tables de votre base de données entraîneraient une duplication importante du code. \n","\n","+ Vous vous souvenez de la fonction **lapply()** ? Vous pouvez l'utiliser à nouveau ici ! Une connexion est déjà codée pour vous, ainsi qu'un vecteur table_names, contenant les noms de toutes les tables de la base de données.\n","\n","####**Instructions**\n","\n","+ Terminez la fonction lapply() pour importer les tables users, tweats et comments en un seul appel. \n","\n","+ Le résultat, une liste de cadres de données, sera stocké dans les tables variables.\n","Imprimez les tables pour vérifier si vous avez bien fait."],"metadata":{"id":"qwXZrhOUNVBj"}},{"cell_type":"code","source":["# Load the DBI package\n","library(DBI)\n","\n","# Connect to the MySQL database: con\n","con <- dbConnect(RMySQL::MySQL(), \n","                 dbname = \"tweater\", \n","                 host = \"courses.csrrinzqubik.us-east-1.rds.amazonaws.com\", \n","                 port = 3306,\n","                 user = \"student\",\n","                 password = \"datacamp\")\n","\n","# Get table names\n","table_names <- dbListTables(con)\n","\n","# Import all tables\n","tables <- lapply(table_names, dbReadTable, conn = con)\n","\n","# Print out tables\n","tables"],"metadata":{"id":"_UsM-LDTNhMe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Quels sont les liens entre les tables ?**\n","\n","+ La connexion à la base de données MySQL con a déjà été créée pour vous. \n","\n","+ tables, une liste contenant les trois tables sous forme de cadres de données que vous avez créés dans l'exercice précédent, est également disponible.\n","\n","+ Si vous regardez de plus près ces tables, vous verrez que la table tweats, par exemple, contient une colonne user_id.\n","+ Les identifiants de cette colonne font référence aux utilisateurs qui ont posté le tweat. \n","\n","+ De même, les commentaires contiennent à la fois une colonne user_id et une colonne tweat_id. Elle indique quel utilisateur a posté un commentaire sur quel tweat.\n","\n","+ Avec ces nouvelles connaissances, pouvez-vous dire qui a posté le tweat sur lequel quelqu'un a commenté \"génial ! merci !\" (commentaire 1012) ?\n","\n","####**Instructions**\n","\n","\n","+ L'utilisateur avec l'id 1, donc Elisabeth.\n","\n","+ Il n'y a pas assez d'informations pour résoudre ce problème.\n","\n","+ L'utilisateur avec l'id 4, donc Thomas.\n","\n","+ **L'utilisateur avec l'id 5, donc Oliver**."],"metadata":{"id":"n7IZuT0oN56C"}},{"cell_type":"code","source":[],"metadata":{"id":"wC6qDduMOGcr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AQHkkgzuORUD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**SQL Requêtes depuis l’intérieur de R**\n","\n","####**1.SQL Requêtes depuis l’intérieur de R**\n","\n","+ Ainsi, la connexion et l’importation à partir d’une base de données sont quelque chose que vous connaissez maintenant.\n","\n","#####**2. dbReadTable()**\n","+ Toutefois, avec dbReadTable,\n","\n","####**3. dbReadTable()**\n","\n","+ Vous importez une table entière. \n","\n","+ Pour l’exemple de l’entreprise qui avait peu de données, ce n’est pas un problème, mais que se passe-t-il si vous avez affaire à une base de données contenant des tables contenant des millions d’enregistrements? \n","\n","+ Vous devez importer la table entière dans R avant de pouvoir effectuer une analyse qui pourrait n’avoir besoin que d’une fraction de ces données.\n","\n","####**4. dbReadTable()**\n","\n","+ S’il y avait un moyen d’effectuer une grande partie du travail de sélection des données\n","\n","####**5. dbReadTable()**\n","+ côté base de données,\n","\n","####**6. dbReadTable()**\n","+ vous n’avez qu’à importer les éléments dont vous avez réellement besoin dans R. C’est beaucoup plus logique, n’est-ce pas?\n","\n","####**7. Importation sélective**\n","+ Je suis heureux de vous dire que c’est possible, tout cela de l’intérieur de R! \n","\n","+ Rappelez-vous que les bases de données relationnelles utilisent généralement SQL comme langage d’interrogation ? \n","\n","+ Eh bien, vous allez écrire ce que l’on appelle des requêtes SQL pour récupérer des données en fonction de critères spécifiques. \n","\n","+ Vous pouvez envoyer ces requêtes via les fonctions R spécifiées par **le package DBI** et implémentées par un package R qui dépend de la base de données que vous utilisez. \n","\n","+ Comme nous travaillons avec des bases de données **MySQL, c’est RMySQL** ici. \n","\n","+ L’écriture de requêtes SQL est un sujet à part entière, je ne traiterai donc que quelques exemples de base afin que vous ayez l’idée.\n","\n","####**8. Société**\n","\n","+ Jetons un coup d’œil à la base de données de l’entreprise, qui contenait des informations sur les ventes de produits de télécommunications effectuées par différents employés.\n","\n","####**9. Société**\n","\n","+ Supposons que nous voulions avoir les noms des employés qui ont commencé après le premier septembre 2012. Comment s’y prendre ?\n","\n","####**10. Charger le paquet et se connecter**\n","\n","+ Dans tous les cas, nous devons commencer par charger le paquet DBI et créer une connexion à la base de données de l’entreprise. \n","\n","+ Ceci est une base de données réelle, vous pouvez donc essayer le code de cette partie vous-même!\n","\n","####**11. Exemple 1**\n","+ Pour résoudre la tâche en cours, vous pouvez lire la table entière des employés, puis la sous-définir à l’aide de la fonction de sous-ensemble. \n","\n","+ Mais il y a un autre moyen. Jetez un coup d’œil à cet appel de la fonction **dbGetQuery**. Le résultat est exactement le même. \n","\n","+ La syntaxe étrange à l’intérieur de la chaîne ici est en fait une requête SQL très courante, qui utilise trois mots-clés SQL: \n","  + **SELECT, FROM et WHERE**. \n","  \n","+ Le mot clé SELECT spécifie la colonne à sélectionner et correspond à l’argument select dans la fonction de sous-ensemble. \n","\n","+ Le mot-clé FROM spécifie la table à partir de laquelle vous souhaitez obtenir des données et correspond au premier argument de la fonction de sous-ensemble. \n","\n","+ Enfin, le mot clé WHERE spécifie une condition qu’un enregistrement de la table doit remplir. \n","\n","+ Si vous lisez cette phrase à haute voix avec quelques ajouts ici et là, cela semble assez naturel: \n","  + « Sélectionnez la colonne nom dans la table employees, où le champ started_at est supérieur au premier septembre 2012. » \n","  \n","+ La première approche et la seconde peuvent sembler similaires, mais la différence conceptuelle est énorme.\n","\n","####**12. Exemple 1**\n","+ Dans le premier cas,\n","\n","####**13. Exemple 1**\n","+ vous importez l’intégralité de la table employees,\n","\n","#####**14. Exemple 1**\n","+ puis faire un sous-ensemble dans R. Dans le second cas,\n","\n","####**15. Exemple 1**\n","+ vous envoyez une requête SQL à la base de données,\n","\n","####**16. Exemple 1**\n","+ Cette requête est exécutée côté base de données, et\n","\n","####**17. Exemple 1**\n","+ seuls les résultats sont importés dans R. \n","\n","+ Si vous avez affaire à d’énormes tables, la deuxième approche est beaucoup plus efficace. Essayons un autre exemple.\n","\n","####**18. Société**\n","+ Supposons que vous souhaitiez sélectionner les produits qui impliquent un contrat,\n","\n","####**19. Société**\n","\n","+ donc où le contrat est un. Pour ces produits, nous nous intéressons à toutes les variables. \n","+ L’ancienne approche consistant à lire le tableau entier, puis à sous-définir\n","\n","####**20. Exemple 2**\n","+ ressemblerait à ceci. La nouvelle approche consistant à envoyer une requête SQL à la base de données et à récupérer le résultat ressemble à ceci. Les résultats sont à nouveau exactement les mêmes. \n","\n","+ Notez que l’étoile après le mot-clé SELECT spécifie de conserver toutes les colonnes de la table products. \n","\n","+ Notez également que dans la requête SQL, vous devez utiliser un seul signe égal pour spécifier une condition pour le mot clé WHERE, au lieu d’un signe égal double, comme vous en avez l’habitude dans R.\n","\n","####**21. Entraînons-nous!**\n","+ Après ce cours intensif sur la syntaxe SQL, voyons comment vous vous comportez dans certains exercices. Bonne chance!"],"metadata":{"id":"Avd_p4LiORlk"}},{"cell_type":"markdown","source":["####**Ajusteur de requêtes (1)**\n","\n","+ Dans votre vie de scientifique des données, vous serez souvent amené à travailler avec d'énormes bases de données contenant des tableaux de plusieurs millions de lignes. \n","\n","+ Si vous souhaitez effectuer des analyses sur ces données, il est possible que vous n'ayez besoin que d'une fraction de ces données.\n","\n","+  Dans ce cas, c'est une bonne idée d'envoyer des requêtes SQL à votre base de données et de n'importer dans R que les données dont vous avez réellement besoin.\n","\n","+ **La fonction dbGetQuery()** est ce dont vous avez besoin. \n","\n","+ Comme d'habitude, vous lui passez d'abord l'objet de connexion. \n","\n","+ Le second argument est une requête SQL sous la forme d'une chaîne de caractères. \n","+ Cet exemple sélectionne la variable âge dans l'ensemble de données des personnes dont le sexe est égal à \"male\" :\n","\n","      dbGetQuery(con, \"SELECT age FROM people WHERE gender = 'male'\")\n","\n","+ Une connexion à la base de données tweater a déjà été codée pour vous.\n","\n","####**Instructions**\n","\n","+ Utilisez **dbGetQuery()** pour créer un cadre de données, elisabeth, qui sélectionne la colonne tweat_id de la table des commentaires où elisabeth est le commentateur, son user_id est 1.\n","\n","+ Imprimez elisabeth pour voir si vous avez interrogé la base de données correctement."],"metadata":{"id":"d6xTtnP_QTMI"}},{"cell_type":"code","source":["# Connect to the database\n","library(DBI)\n","con <- dbConnect(RMySQL::MySQL(),\n","                 dbname = \"tweater\",\n","                 host = \"courses.csrrinzqubik.us-east-1.rds.amazonaws.com\",\n","                 port = 3306,\n","                 user = \"student\",\n","                 password = \"datacamp\")\n","\n","# Import tweat_id column of comments where user_id is 1: elisabeth\n","elisabeth <- dbGetQuery(con, \"SELECT tweat_id FROM comments WHERE user_id = 1\")\n","\n","# Print elisabeth\n","elisabeth"],"metadata":{"id":"cvwz6MYOQJdK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Ajusteur de requêtes (2)**\n","\n","\n","+ Outre la vérification de l'égalité, vous pouvez également vérifier les relations moins que et plus que, avec < et >, tout comme dans R.\n","\n","+ con, une connexion à la base de données de tweater, est à nouveau disponible.\n","\n","####**Instructions**\n","\n","+ Créez un cadre de données, latest, qui sélectionne la colonne post de la table tweats où la date est supérieure à '2015-09-21'.\n","+ Imprimez latest."],"metadata":{"id":"joqd182UQ96a"}},{"cell_type":"code","source":["# Connect to the database\n","library(DBI)\n","con <- dbConnect(RMySQL::MySQL(),\n","                 dbname = \"tweater\",\n","                 host = \"courses.csrrinzqubik.us-east-1.rds.amazonaws.com\",\n","                 port = 3306,\n","                 user = \"student\",\n","                 password = \"datacamp\")\n","\n","# Import post column of tweats where date is higher than '2015-09-21': latest\n","latest <- dbGetQuery(con, \"SELECT post FROM tweats WHERE date > '2015-09-21'\")\n","\n","# Print latest\n","latest"],"metadata":{"id":"zkh9STPZRFtM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Ajusteur de requêtes (3)**\n","+ Supposons que vous ayez une table de personnes, avec un tas d'informations. \n","\n","+ Cette fois, vous voulez connaître l'âge et le pays des hommes mariés. \n","\n","+ A condition qu'il y ait une colonne mariée qui vaut 1 lorsque la personne en question est mariée, la requête suivante fonctionnerait.\n","\n","      SELECT age, pays\n","        FROM personnes\n","          WHERE gender = \"male\" AND married = 1\n","\n","\n","+ Pouvez-vous utiliser une approche similaire pour une requête plus spécialisée sur la base de données tweater ?\n","\n","####**Instructions**\n","\n","+ Créez un cadre de données R, specific, qui sélectionne la colonne message de la table des commentaires où le tweat_id est 77 et le user_id est supérieur à 4.\n","+ Imprimez specific."],"metadata":{"id":"XX4hx4IORXsY"}},{"cell_type":"code","source":["# Connect to the database\n","library(DBI)\n","con <- dbConnect(RMySQL::MySQL(),\n","                 dbname = \"tweater\",\n","                 host = \"courses.csrrinzqubik.us-east-1.rds.amazonaws.com\",\n","                 port = 3306,\n","                 user = \"student\",\n","                 password = \"datacamp\")\n","\n","# Create data frame specific\n","specific <- dbGetQuery(con, \"SELECT message FROM comments WHERE tweat_id = 77 AND user_id > 4 \")\n","\n","# Print specific\n","specific"],"metadata":{"id":"Ltf-B89dRkoo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Ajusteur de requêtes (4)**\n","+ Il existe également des fonctions SQL dédiées que vous pouvez utiliser dans la clause WHERE d'une requête SQL. \n","\n","+ Par exemple, CHAR_LENGTH() renvoie le nombre de caractères d'une chaîne.\n","\n","####**Instructions**\n","\n","+ Créez un cadre de données, short, qui sélectionne les colonnes id et name de la table users où le nombre de caractères dans le nom est strictement inférieur à 5.\n","\n","+ Imprimez short."],"metadata":{"id":"MbhN81z_SxJP"}},{"cell_type":"code","source":["# Connect to the database\n","library(DBI)\n","con <- dbConnect(RMySQL::MySQL(),\n","                 dbname = \"tweater\",\n","                 host = \"courses.csrrinzqubik.us-east-1.rds.amazonaws.com\",\n","                 port = 3306,\n","                 user = \"student\",\n","                 password = \"datacamp\")\n","\n","# Create data frame short\n","short <- dbGetQuery(con, \"SELECT id, name FROM users WHERE CHAR_LENGTH(name) <5\")\n","\n","# Print short\n","short"],"metadata":{"id":"ULo2jHR7S5Fw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Voici la folie des requêtes !**\n","\n","+ Bien sûr, le langage SQL ne s'arrête pas aux trois mots-clés **SELECT, FROM et WHERE**. \n","\n","+ Un autre mot-clé très souvent utilisé est JOIN, et plus précisément INNER JOIN. Prenez cet appel par exemple :\n","\n","      SELECT name, post\n","        FROM users INNER JOIN tweats on users.id = user_id\n","        WHERE date > \"2015-09-19\"\n","\n","+ Ici, la table users est jointe à la table tweats. \n","\n","+ Cela est possible car la colonne id de la table users correspond à la colonne user_id de la table tweats. \n","\n","+ Remarquez également comment le nom, provenant de la table users, et le message et la date, provenant de la table tweats, peuvent être référencés sans problème.\n","\n","+ Pouvez-vous prédire le résultat de la requête suivante ?\n","\n","      SELECT post, message\n","        FROM tweats INNER JOIN comments on tweats.id = tweat_id\n","        WHERE tweat_id = 77\n","\n","\n","+ Une connexion à la base de données tweats est déjà disponible en tant que con ; n'hésitez pas à expérimenter !\n","\n","####**Instructions**\n","\n","####**Réponses possibles**\n","\n","+ En essayant d'obtenir les résultats de cette requête SQL, vous obtenez une erreur.\n","\n","+ **Une table avec quatre observations, contenant deux colonnes : post et message.**\n","\n","+ Une table avec six observations, contenant toutes les colonnes de la table tweats.\n","\n","+ Une table avec six observations, contenant les colonnes post et message.\n","\n","\n","\n"],"metadata":{"id":"MGyNJy4_TMH_"}},{"cell_type":"code","source":[],"metadata":{"id":"B8bYaiTFUNmv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Internes DBI**\n","\n","####**1. Internes DBI**\n","+ Revenons à un appel de fonction dbGetQuery d’avant.\n","\n","####**2. dbGetQuery()**\n","\n","\n","+ C’était incroyablement facile à utiliser. Il suffit de passer l’objet de connexion et une requête SQL, et vous obtenez un résultat. \n","\n","+ Ce qu’il fait réellement en arrière-plan, c’est envoyer une requête, avec **dbSendQuery**, comme ceci. \n","\n","+ Cette fonction renvoie un résultat, mais celui-ci ne contient en fait aucun enregistrement que vous souhaitez importer. \n","\n","+ Pour cela, vous devez utiliser la fonction **dbFetch**. \n","\n","+ Enfin, vous devez effacer manuellement le résultat. \n","\n","+ **La combinaison de dbSendQuery, dbFetch et dbClearResult donne exactement le même résultat que dbGetQuery** auparavant, alors pourquoi faire cela ?\n","\n","+  Eh bien, les appels de requête dbFetch vous permettent de spécifier un nombre maximum d’enregistrements à récupérer par extraction. \n","\n","+ Cela peut être utile lorsque vous devez charger des tonnes d’enregistrements, mais que vous souhaitez le faire morceau par morceau. Supposons, par exemple,\n","\n","####**3. dbFetch() un par un**\n","\n","+ Vous souhaitez obtenir le résultat de la requête précédente, enregistrement par enregistrement. \n","\n","+ Vous pouvez utiliser cette construction pour cela, avec la même requête SQL qu’auparavant. \n","\n","+ Ce code envoie d’abord une requête à la base de données, puis entre dans une boucle while qui vérifie si le résultat de la requête contient toujours des données qui n’ont pas encore été extraites. \n","\n","+ S’il y a encore des données disponibles, les morceaux sont récupérés enregistrement par enregistrement, et ce morceau est imprimé à chaque itération.\n","\n","+ La sortie montre en effet les deux enregistrements, imprimés séparément, l’un après l’autre. \n","\n","+ Dans cet exemple de jouet, cette approche n’est pas vraiment utile, mais si vous travaillez sur un algorithme super compliqué qui implique des millions d’enregistrements de base de données, vous voudrez peut-être envisager un traitement des données en morceaux, non? Après tout votre travail acharné sur la base de données,\n","\n","####**4. Déconnectez-vous**\n","\n","+ N’oubliez pas de vous en déconnecter. Essayez ces fonctions DBI de bas niveau dans les exercices.\n","\n","####**5. Entraînons-nous!**\n","+ Dans le prochain chapitre, je reviendrai vous en dire plus sur l’importation de données à partir du Web. Rendez-vous là-bas!"],"metadata":{"id":"Ha-GUoO-TryA"}},{"cell_type":"markdown","source":["###**EXERCICES**\n","\n","####**Envoyer - Récupérer - Effacer**\n","\n","+ Vous avez utilisé dbGetQuery() plusieurs fois maintenant. \n","\n","+ Il s'agit d'une fonction virtuelle du paquet **DBI**, mais elle est en fait implémentée par le paquet **RMySQL**. \n","\n","+ En coulisses, les étapes suivantes sont réalisées :\n","\n","  + Envoi de la requête spécifiée avec **dbSendQuery()** ;\n","  + Récupération du résultat de l'exécution de la requête sur la base de données avec **dbFetch()** ;\n","  + Effacer le résultat avec **dbClearResult()**.\n","\n","\n","+ N'utilisons pas **dbGetQuery()** cette fois-ci et implémentons les étapes ci-dessus. \n","\n","+ C'est fastidieux à écrire, mais cela vous donne la possibilité de récupérer le résultat de la requête par morceaux plutôt qu'en une seule fois. \n","+ Vous pouvez le faire en spécifiant l'argument n dans dbFetch().\n","\n","####**Instructions**\n","\n","+ Inspectez l'appel dbSendQuery() qui a déjà été codé pour vous. \n","\n","+ Il sélectionne les commentaires pour les utilisateurs avec un id supérieur à 4.\n","\n","\n","+ Utilisez dbFetch() deux fois. Dans le premier appel, importez seulement deux enregistrements du résultat de la requête en mettant l'argument n à 2. \n","\n","+ Dans le second appel, importez toutes les requêtes restantes (ne spécifiez pas n). \n","\n","+ Dans les deux appels, imprimez simplement les cadres de données résultants.\n","\n","\n","+ Effacez les résultats avec dbClearResult()."],"metadata":{"id":"PYxHCMErWIXe"}},{"cell_type":"code","source":["# Connect to the database\n","library(DBI)\n","con <- dbConnect(RMySQL::MySQL(),\n","                 dbname = \"tweater\",\n","                 host = \"courses.csrrinzqubik.us-east-1.rds.amazonaws.com\",\n","                 port = 3306,\n","                 user = \"student\",\n","                 password = \"datacamp\")\n","\n","# Send query to the database\n","res <- dbSendQuery(con, \"SELECT * FROM comments WHERE user_id > 4\")\n","\n","# Use dbFetch() twice\n","dbFetch(res, n=2)\n","dbFetch(res)\n","\n","# Clear res\n","dbClearResult(res)"],"metadata":{"id":"Cfjt1ve-ULWg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Soyez poli et ...**\n","+ Chaque fois que vous vous connectez à une base de données en utilisant dbConnect(), vous créez une nouvelle connexion à la base de données que vous référencez. \n","\n","+ RMySQL spécifie automatiquement un maximum de connexions ouvertes et ferme certaines des connexions pour vous, mais tout de même : il est toujours poli de se déconnecter manuellement de la base de données par la suite. Vous le faites avec la fonction dbDisconnect().\n","\n","+ Le code qui vous connecte à la base de données est déjà disponible, pouvez-vous terminer le script ?\n","\n","####**Instructions**\n","\n","+ En utilisant la technique que vous préférez, construisez un cadre de données long_tweats. \n","\n","+ Il sélectionne les colonnes post et date à partir des observations dans tweats où la longueur de caractères de la variable post dépasse 40.\n","\n","+ Imprimez long_tweats.\n","\n","\n","+ Déconnectez-vous de la base de données en utilisant dbDisconnect()."],"metadata":{"id":"m6CctHWGYgY2"}},{"cell_type":"code","source":["# Connect to the database\n","library(DBI)\n","con <- dbConnect(RMySQL::MySQL(),\n","                 dbname = \"tweater\",\n","                 host = \"courses.csrrinzqubik.us-east-1.rds.amazonaws.com\",\n","                 port = 3306,\n","                 user = \"student\",\n","                 password = \"datacamp\")\n","\n","# Create the data frame  long_tweats\n","long_tweats <- long_tweats <- dbGetQuery(con, \"SELECT post, date FROM tweats WHERE CHAR_LENGTH(post) > 40\")\n","\n","# Print long_tweats\n","long_tweats\n","\n","# Disconnect from the database\n","dbDisconnect(con)"],"metadata":{"id":"YnbNNZPLTj2i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**HTTP**\n","\n","####**1. HTTP**\n","\n","+ De plus en plus d’informations avec lesquelles vous travaillerez en tant que data scientist résident sur le Web.\n","\n","####**2. Données sur le web**\n","\n","+ En fait, vous avez déjà travaillé avec de telles données. Vous souvenez-vous de la façon dont vous vous êtes connecté à une base de données relationnelle distante pour obtenir les informations exactes dont vous aviez besoin ? \n","\n","+ Le package DBI a résumé le fait que les données se trouvaient dans un emplacement distant et a tout corrigé pour vous. \n","\n","+ Dans ce chapitre, vous allez examiner les formats de fichiers qui sont particulièrement utiles lorsqu’ils sont utilisés pour la technologie Web, comme le fichier JSON. \n","\n","+ Je vais d’abord discuter de ce qui se passe réellement dans les coulisses lorsque vous importez des données sur le Web. \n","\n","+ Pour comprendre ce qui se passe dans les exemples qui suivent, je vais vous donner un cours intensif sur les bases de HTTP,\n","\n","####**3. HTTP**\n","\n","+ abréviation de HyperText Transfer Protocol. Il s’agit essentiellement d’un système de règles sur la façon dont les données doivent être échangées entre les ordinateurs. \n","\n","+ En bref, HTTP est le langage du web. \n","\n","+ Si vous accédez à une page Web, par exemple, votre ordinateur, le client, envoie en fait un\n","\n","####**4. HTTP**\n","+ requête HTTP au\n","\n","####**5. HTTP**\n","+ serveur. Le serveur renvoie ensuite\n","\n","####**6. HTTP**\n","+ données représentant la page Web, donc il envoie une réponse, et la page Web apparaît sur votre écran. \n","+ Il existe plusieurs méthodes HTTP, comme on les appelle. \n","+ Pour obtenir simplement une page Web à partir d’un serveur,\n","\n","####**7. HTTP**\n","+ vous utilisez la méthode GET, par exemple. \n","\n","+ Outre GET, il existe également d’autres méthodes HTTP, mais ne nous y attardons pas ici. \n","\n","+ Au lieu de cela, jetons un coup d’œil à quelques exemples dont vous vous souvenez peut-être des chapitres précédents, mais cette fois, toutes les données résideront sur le Web.\n","\n","####**8. Exemple : CSV**\n","\n","\n","+ Commençons par le fichier states-dot-csv par exemple, qui se trouve sur ce lien. \n","\n","+ Le flux de travail typique consiste à télécharger manuellement le fichier via votre navigateur Web préféré, puis à pointer vers le chemin d’accès à l’intérieur du fichier CSV Read Dot. Toutefois\n","\n","####**9. Exemple : CSV**\n","\n","\n","+ Cela peut être fait beaucoup plus facilement! Jetez un coup d’œil à cette ligne, où nous passons simplement l’URL sous forme de chaîne de caractères. \n","\n","+ Le résultat est exactement le même : un cadre de données avec 5 observations et 4 variables. Comment cela pourrait-il être si facile? \n","\n","+ Eh bien, dans les coulisses, R comprend que vous avez fait référence à une URL et la demande à l’aide d’une requête HTTP GET. \n","\n","+ Le serveur répond avec le fichier csv, que R peut ensuite lire comme il le faisait auparavant. \n","\n","+ Plutôt sympa, hein? De nos jours, il existe de nombreux sites Web qui n’acceptent que les connexions sécurisées. \n","\n","+ Vous ne pouvez visiter ces sites Web ou télécharger leurs fichiers qu’avec le préfixe http_S_. \n","\n","+ Est-ce que R sait aussi comment gérer cela ? Eh bien, découvrons avec le même fichier CSV, mais cette fois\n","\n","####**10. Exemple : CSV**\n","+ avec le préfixe HTTPS. \n","\n","+ Cela fonctionne tout de même, génial.\n","\n","+ Le support HTTPS est intégré à R depuis R version 3 point 2 point 2. Tester l’importation de données à partir du Web\n","\n","####**11. Entraînons-nous!**\n","+ vous-même dans les exercices!"],"metadata":{"id":"hOwFzYFdY2PY"}},{"cell_type":"markdown","source":["###**EXERCICES**\n","####**Importer des fichiers plats depuis le web**\n","\n","+ Dans la partie ci-dessus, vous avez vu que les fonctions utils pour importer des données de fichiers plats, telles que **read.csv() et read.delim()**, sont capables d'importer automatiquement à partir d'URLs qui pointent vers des fichiers plats sur le web.\n","\n","+ Vous devez vous demander si le paquet alternatif de Hadley Wickham, readr, est aussi puissant. \n","\n","+ Eh bien, découvrez-le dans cet exercice ! Les URLs d'un fichier .csv et d'un fichier .delim sont déjà codées pour vous. \n","\n","+ C'est à vous d'importer les données. Si cela fonctionne, c'est-à-dire...\n","\n","####**Instructions**\n","\n","+ Chargez le paquet readr.\n","\n","\n","+ Utilisez url_csv pour lire le fichier .csv vers lequel il pointe. Utilisez la fonction read_csv(). Le .csv contient les noms des colonnes dans la première ligne. \n","\n","+ Enregistrez le cadre de données résultant en tant que pools.\n","\n","\n","+ De même, utilisez url_delim pour lire le fichier .txt en ligne. Utilisez la fonction read_tsv() et enregistrez le résultat en tant que potatoes.\n","\n","\n","+ Imprimez pools et potatoes. Est-ce que cela semble correct ?\n"],"metadata":{"id":"FmyLQFFZbWV9"}},{"cell_type":"code","source":["install.packages(\"readr\")\n","install.packages(\"gdata\")\n","install.packages(\"readxl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HDMB3DjHb4Wk","executionInfo":{"status":"ok","timestamp":1670700159349,"user_tz":-60,"elapsed":89184,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"8333f031-d3b5-4af0-d667-000db3aec776"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Installing package into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","\n","Installing package into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","\n","also installing the dependency ‘gtools’\n","\n","\n","Installing package into ‘/usr/local/lib/R/site-library’\n","(as ‘lib’ is unspecified)\n","\n"]}]},{"cell_type":"code","source":["# Load the readr package\n","library(readr)\n","\n","# Import the csv file: pools\n","url_csv <- \"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/swimming_pools.csv\"\n","pools <- read_csv(url_csv)\n","\n","# Import the txt file: potatoes\n","url_delim <- \"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/potatoes.txt\"\n","potatoes <- read_tsv(url_delim)\n","\n","# Print pools and potatoes\n","pools\n","potatoes"],"metadata":{"id":"moUtMb9Dbr71"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Importation sécurisée**\n","\n","\n","+ Dans les exercices précédents, vous avez travaillé avec des URL qui commencent toutes par http://. \n","\n","+ Il existe cependant une alternative plus sûre au HTTP, à savoir HTTPS, qui signifie HyperText Transfer Protocol Secure. \n","\n","+ N'oubliez pas ceci : HTTPS est relativement sûr, HTTP ne l'est pas.\n","\n","+ Heureusement pour nous, vous pouvez utiliser les fonctions d'importation standard avec les connexions https:// depuis la version 3.2.2 de R.\n","\n","####**Instructions**\n","\n","+ Regardez l'URL dans url_csv. Elle utilise une connexion sécurisée, https://.\n","\n","+ Utilisez read.csv() pour importer le fichier dans url_csv. Le fichier .csv auquel il fait référence contient des noms de colonnes dans la première ligne. Appelez-le pools1.\n","\n","+ Chargez le paquet readr. Il est déjà installé sur les serveurs de DataCamp.\n","\n","+ Utilisez read_csv() pour lire le même fichier .csv dans url_csv. Appelez-le pools2.\n","\n","+ Imprimez la structure de pools1 et pools2. On dirait que l'importation s'est déroulée aussi bien qu'avec une connexion http normale !"],"metadata":{"id":"3Xb3t2JTcXwF"}},{"cell_type":"code","source":["# https URL to the swimming_pools csv file.\n","url_csv <- \"https://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/swimming_pools.csv\"\n","\n","# Import the file using read.csv(): pools1\n","pools1 <- read.csv(url_csv)\n","\n","# Load the readr package\n","library(readr)\n","\n","# Import the file using read_csv(): pools2\n","pools2 <- read_csv(url_csv)\n","\n","\n","# Print the structure of pools1 and pools2\n","str(pools1)\n","str(pools2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WnleNdzgcjb_","executionInfo":{"status":"ok","timestamp":1670699529356,"user_tz":-60,"elapsed":844,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"3d4c3ab4-7d0b-468e-a607-75b80d6cc7f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[1mRows: \u001b[22m\u001b[34m20\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m4\u001b[39m\n","\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n","\u001b[1mDelimiter:\u001b[22m \",\"\n","\u001b[31mchr\u001b[39m (2): Name, Address\n","\u001b[32mdbl\u001b[39m (2): Latitude, Longitude\n","\n","\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n","\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"]},{"output_type":"stream","name":"stdout","text":["'data.frame':\t20 obs. of  4 variables:\n"," $ Name     : chr  \"Acacia Ridge Leisure Centre\" \"Bellbowrie Pool\" \"Carole Park\" \"Centenary Pool (inner City)\" ...\n"," $ Address  : chr  \"1391 Beaudesert Road, Acacia Ridge\" \"Sugarwood Street, Bellbowrie\" \"Cnr Boundary Road and Waterford Road Wacol\" \"400 Gregory Terrace, Spring Hill\" ...\n"," $ Latitude : num  -27.6 -27.6 -27.6 -27.5 -27.4 ...\n"," $ Longitude: num  153 153 153 153 153 ...\n","spc_tbl_ [20 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n"," $ Name     : chr [1:20] \"Acacia Ridge Leisure Centre\" \"Bellbowrie Pool\" \"Carole Park\" \"Centenary Pool (inner City)\" ...\n"," $ Address  : chr [1:20] \"1391 Beaudesert Road, Acacia Ridge\" \"Sugarwood Street, Bellbowrie\" \"Cnr Boundary Road and Waterford Road Wacol\" \"400 Gregory Terrace, Spring Hill\" ...\n"," $ Latitude : num [1:20] -27.6 -27.6 -27.6 -27.5 -27.4 ...\n"," $ Longitude: num [1:20] 153 153 153 153 153 ...\n"," - attr(*, \"spec\")=\n","  .. cols(\n","  ..   Name = \u001b[31mcol_character()\u001b[39m,\n","  ..   Address = \u001b[31mcol_character()\u001b[39m,\n","  ..   Latitude = \u001b[32mcol_double()\u001b[39m,\n","  ..   Longitude = \u001b[32mcol_double()\u001b[39m\n","  .. )\n"," - attr(*, \"problems\")=<externalptr> \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"IP1BwApwa83v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Téléchargement de fichiers**\n","\n","####**1. Téléchargement de fichiers**\n","\n","+ Semblable à ce que nous avons fait dans la partie précédente,\n","\n","#####**2. Exemple : Excel**\n","\n","+ utilisons maintenant le package readxl pour importer des données Excel stockées à cette URL. \n","\n","+ Le read_excel fonctionnera-t-il hors des sentiers battus ici?\n","\n","+ Apparemment, readxl ne sait pas comment gérer les fichiers Excel stockés sur le Web, bien que je m’attende à ce que Hadley Wickham ajoute cette fonctionnalité dans les versions futures. \n","\n","+ Cela signifie-t-il que nous devrons télécharger manuellement le fichier, puis pointer vers le fichier local comme vous le feriez auparavant? Pas du tout!\n","\n","####**3. download.file()**\n","\n","\n","+ Vous pouvez utiliser télécharger le fichier point ici, une fonction du paquet utils. \n","\n","+ Définissons d’abord l’URL et le chemin de destination, donc où nous voulons placer le fichier téléchargé sur notre système. \n","\n","+ Je vais appeler le fichier local_cities point xlsx et le placer dans mon répertoire personnel.\n","\n","\n","+ Si vous utilisez maintenant télécharger le fichier point avec l’url comme premier argument et le chemin de destination comme deuxième argument, vous êtes prêt à partir. Parfait. \n","\n","+ Ce que le fichier point de téléchargement a fait est simple. \n","\n","+ Il a effectué une requête GET à l’URL que vous avez spécifiée et stocké le contenu de la réponse à l’emplacement que vous avez spécifié. \n","\n","+ La dernière étape consiste à utiliser la fonction read_excel d’avant pour importer les données Excel à partir du fichier local cette fois. Nous pouvons à nouveau utiliser la variable dest_path ici.\n","\n","####**4. Pourquoi download.file()?**\n","\n","+ Vous vous demandez peut-être pourquoi l’utilisation du fichier de points de téléchargement est utile. \n","\n","+ La réponse est encore une fois : la reproductibilité. \n","\n","+ Vous pouvez spécifier des URL dans vos scripts R et les télécharger via les fonctions R au lieu de naviguer manuellement sur le Web, ce qui nécessite plusieurs clics de souris. \n","\n","+ Il y a beaucoup plus à apprendre sur l’exécution de requêtes GET et d’autres requêtes HTTP à partir de R. \n","\n","+ Dans certains cas, vous devrez vous authentifier avant de pouvoir télécharger des fichiers et transmettre des paramètres supplémentaires à votre requête GET. \n","\n","+ Si vous voulez en savoir plus à ce sujet, je vous suggère de consulter le paquet httr de Hadley Wickham.\n","\n","####**5. Entraînons-nous!**\n","+ Dirigez-vous vers les exercices pour un peu plus de pratique maintenant, amusez-vous!"],"metadata":{"id":"cb_kMrZmdFJ7"}},{"cell_type":"markdown","source":["###**EXERCICES**\n","\n","####**Importer des fichiers Excel depuis le web**\n","\n","+ Lorsque vous avez appris à connaître gdata, il a déjà été mentionné que gdata peut gérer les fichiers .xls qui se trouvent sur Internet. \n","\n","+ readxl ne le peut pas, du moins pas encore. \n","\n","+ L'URL avec laquelle vous allez travailler est déjà disponible dans l'exemple de code. \n","\n","+ Vous l'importerez une fois en utilisant gdata et une fois avec le paquet readxl via une solution de contournement.\n","\n","####**Instructions**\n","\n","+ Chargez les paquets readxl et gdata. \n","\n","+ Importez le fichier .xls situé à l'URL url_xls en utilisant read.xls() de gdata. \n","\n","+ Stockez le cadre de données résultant comme excel_gdata.\n","\n","\n","+ Vous ne pouvez pas utiliser read_excel() directement avec une URL. \n","\n","+ Suivez les instructions suivantes pour contourner ce problème :\n","  + Utilisez download.file() pour télécharger le fichier .xls derrière l'URL et le stocker localement sous le nom de \"local_latitude.xls\".\n","\n","  + Appelez read_excel() pour importer le fichier local, \"local_latitude.xls\". \n","  \n","  + Nommez le cadre de données résultant excel_readxl."],"metadata":{"id":"VFGVZzugebLi"}},{"cell_type":"code","source":["# Load the readxl and gdata package\n","library(gdata)\n","library(readxl)\n","\n","\n","# Specification of url: url_xls\n","url_xls <- \"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/latitude.xls\"\n","\n","# Import the .xls file with gdata: excel_gdata\n","excel_gdata <- read.xls(url_xls)\n","\n","# Download file behind URL, name it local_latitude.xls\n","download.file(url_xls, destfile = \"local_latitude.xls\", quiet = TRUE, mode = \"wb\")\n","\n","# Import the local .xls file with readxl: excel_readxl\n","excel_readxl <- read_excel(\"local_latitude.xls\")"],"metadata":{"id":"egRpVjqddzf1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Téléchargement de n'importe quel fichier, sécurisé ou non**\n","\n","+ Dans l'exercice précédent, vous avez vu comment vous pouvez lire des fichiers Excel sur le Web à l'aide du package **read_excel** en téléchargeant d'abord le fichier avec la **fonction download.file()**.\n","\n","+ Mais ce n'est pas tout : avec **download.file()**, vous pouvez télécharger n'importe quel type de fichier sur le Web, en utilisant **HTTP et HTTPS** : \n","  + des images, des fichiers exécutables, mais aussi des fichiers .RData. \n","  \n","+ **Un fichier RData est un format très efficace pour stocker les données R**.\n","\n","+ Vous pouvez charger des données à partir d'un fichier RData en utilisant la fonction load(), mais cette fonction n'accepte pas une chaîne d'URL comme argument. \n","\n","+ Dans cet exercice, vous allez d'abord télécharger le fichier RData en toute sécurité, puis importer le fichier de données local.\n","\n","####**Instructions**\n","\n","+ Jetez un coup d'œil à l'URL dans url_rdata. \n","\n","+ Elle utilise une connexion sécurisée, https://. Cette URL pointe vers un fichier RData contenant un cadre de données avec quelques mesures sur différents types de vin.\n","\n","\n","+ Téléchargez le fichier à url_rdata en utilisant download.file(). \n","\n","+ Appelez le fichier \"wine_local.RData\" dans votre répertoire de travail.\n","\n","\n","+ Chargez le fichier que vous avez créé, wine_local.RData, à l'aide de la fonction load(). \n","+ Elle prend un argument, le chemin d'accès au fichier, qui est juste le nom du fichier dans notre cas. \n","\n","+ Après avoir exécuté cette commande, la variable wine sera automatiquement disponible dans votre espace de travail.\n","\n","\n","+ Imprimez le summary() de l'ensemble de données wine."],"metadata":{"id":"RbEP3A9qfM2J"}},{"cell_type":"code","source":["# https URL to the wine RData file.\n","url_rdata <- \"https://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/wine.RData\"\n","\n","# Download the wine file to your working directory\n","download.file(url_rdata, destfile = \"wine_local.RData\")\n","\n","# Load the wine data into your workspace using load()\n","load(\"wine_local.RData\")\n","\n","# Print out the summary of the wine data\n","summary(wine)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"x9azsQMFfk6T","executionInfo":{"status":"ok","timestamp":1670700335985,"user_tz":-60,"elapsed":438,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"f01353cd-ecc4-4862-ab7f-3c4f54a2c802"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["    Alcohol        Malic acid        Ash        Alcalinity of ash\n"," Min.   :11.03   Min.   :0.74   Min.   :1.360   Min.   :10.60    \n"," 1st Qu.:12.36   1st Qu.:1.60   1st Qu.:2.210   1st Qu.:17.20    \n"," Median :13.05   Median :1.87   Median :2.360   Median :19.50    \n"," Mean   :12.99   Mean   :2.34   Mean   :2.366   Mean   :19.52    \n"," 3rd Qu.:13.67   3rd Qu.:3.10   3rd Qu.:2.560   3rd Qu.:21.50    \n"," Max.   :14.83   Max.   :5.80   Max.   :3.230   Max.   :30.00    \n","   Magnesium      Total phenols     Flavanoids    Nonflavanoid phenols\n"," Min.   : 70.00   Min.   :0.980   Min.   :0.340   Min.   :0.1300      \n"," 1st Qu.: 88.00   1st Qu.:1.740   1st Qu.:1.200   1st Qu.:0.2700      \n"," Median : 98.00   Median :2.350   Median :2.130   Median :0.3400      \n"," Mean   : 99.59   Mean   :2.292   Mean   :2.023   Mean   :0.3623      \n"," 3rd Qu.:107.00   3rd Qu.:2.800   3rd Qu.:2.860   3rd Qu.:0.4400      \n"," Max.   :162.00   Max.   :3.880   Max.   :5.080   Max.   :0.6600      \n"," Proanthocyanins Color intensity       Hue           Proline      \n"," Min.   :0.410   Min.   : 1.280   Min.   :1.270   Min.   : 278.0  \n"," 1st Qu.:1.250   1st Qu.: 3.210   1st Qu.:1.930   1st Qu.: 500.0  \n"," Median :1.550   Median : 4.680   Median :2.780   Median : 672.0  \n"," Mean   :1.587   Mean   : 5.055   Mean   :2.604   Mean   : 745.1  \n"," 3rd Qu.:1.950   3rd Qu.: 6.200   3rd Qu.:3.170   3rd Qu.: 985.0  \n"," Max.   :3.580   Max.   :13.000   Max.   :4.000   Max.   :1680.0  "]},"metadata":{}}]},{"cell_type":"markdown","source":["####**Lecture d'un fichier texte à partir du Web**\n","\n","+ Wow, vous avez appris beaucoup de façons d'importer un fichier de données depuis le web dans les exercices précédents.\n","+ Voyons si vous pouvez vous souvenir de ce qui est possible et de ce qui ne l'est pas.\n","\n","+ Quelle méthode d'importation de données n'est PAS possible ?\n","\n","####**Instructions**\n","\n","\n","+ Importer un fichier .csv résidant sur le Web en utilisant l'URL avec read.csv().\n","\n","+ Télécharger un fichier excel distant et l'enregistrer dans votre répertoire de travail en utilisant download.file().\n","\n","+ Importer un fichier .txt résidant sur le web en utilisant l'URL avec read_tsv().\n","\n","+ **Utiliser la fonction load() pour charger un fichier RData distant dans l'espace de travail avec seulement la chaîne URL**.\n","\n","\n","\n"],"metadata":{"id":"UbBNx4RMgBzy"}},{"cell_type":"markdown","source":["####**HTTP ? httr ! (1)**\n","+ Télécharger un fichier sur Internet signifie envoyer une requête GET et recevoir le fichier demandé. \n","\n","+ En interne, toutes les fonctions discutées précédemment utilisent une requête GET pour télécharger des fichiers.\n","\n","+ **httr fournit une fonction pratique, GET(), pour exécuter cette requête GET**. \n","\n","+ Le résultat est un objet de réponse, qui permet d'accéder facilement au code d'état, au type de contenu et, bien sûr, au contenu réel.\n","\n","+ Vous pouvez extraire le contenu de la requête à l'aide de la fonction **content()**. \n","\n","+ Au moment de la rédaction du présent document, il existe trois façons d'extraire ce contenu : en tant qu'objet brut, en tant que vecteur de caractères ou en tant qu'objet R, tel qu'une liste. \n","\n","+ Si vous n'indiquez pas à content() comment récupérer le contenu par le biais de l'argument as, il fera de son mieux pour déterminer le type le plus approprié en fonction du content-type.\n","\n","####**Instructions**\n","\n","+ Chargez le paquet httr. .\n","\n","+ Utilisez GET() pour obtenir l'URL stockée dans url. Stockez le résultat de cet appel GET() comme resp.\n","\n","+ Imprimer l'objet resp. Quelles sont les informations qu'il contient ?\n","\n","+ Obtenez le contenu de resp en utilisant content() et définissez l'argument as à \"raw\". \n","\n","+ Assignez le vecteur résultant à raw_content.\n","\n","+ Imprimez les premières valeurs dans raw_content avec head()."],"metadata":{"id":"PE43qJ9sgvCB"}},{"cell_type":"code","source":["install.packages(\"httr\")"],"metadata":{"id":"EyWpZTDWiYAI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the httr package\n","library(httr)\n","\n","# Get the url, save response to resp\n","url <- \"http://www.example.com/\"\n","resp <- GET(url)\n","\n","# Print resp\n","resp\n","\n","# Get the raw content of resp: raw_content\n","raw_content <- content(resp, as = \"raw\")\n","\n","# Print the head of raw_content\n","head(raw_content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"id":"AE9WqE3ciS9S","executionInfo":{"status":"ok","timestamp":1670700988704,"user_tz":-60,"elapsed":433,"user":{"displayName":"etienne koa","userId":"01067828653934976478"}},"outputId":"27ecbd5c-43b9-4226-fb15-f599081ba05a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Response [http://www.example.com/]\n","  Date: 2022-12-10 19:36\n","  Status: 200\n","  Content-Type: text/html; charset=UTF-8\n","  Size: 1.26 kB\n","<!doctype html>\n","<html>\n","<head>\n","    <title>Example Domain</title>\n","\n","    <meta charset=\"utf-8\" />\n","    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n","    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n","    <style type=\"text/css\">\n","    body {\n","..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["[1] 3c 21 64 6f 63 74"]},"metadata":{}}]},{"cell_type":"markdown","source":["####**HTTP ? httr ! (2)**\n","+ Le contenu web ne se limite pas aux pages HTML et aux fichiers stockés sur des serveurs distants tels que les instances Amazon S3 de DataCamp. \n","\n","+ Il existe de nombreux autres formats de données. \n","\n","+ Un format très courant est le JSON. \n","\n","+ Ce format est très souvent utilisé par ce que l'on appelle les API Web, des interfaces de serveurs Web avec lesquelles vous, en tant que client, pouvez communiquer pour obtenir ou stocker des informations de manière plus complexe.\n","\n","+ Vous apprendrez à connaître les API Web et JSON dans la partie et les exercices qui suivent, mais un peu d'expérimentation ne fait jamais de mal, n'est-ce pas ?\n","\n","####**Instructions**\n","\n","+ Utilisez GET() pour obtenir l'url qui a déjà été spécifié dans l'exemple de code. Stockez la réponse en tant que resp.\n","\n","+ Imprimez resp. Quel est le content-type ?\n","Utilisez content() pour obtenir le contenu de resp. Définissez l'argument as à \"text\".\n","\n","+ Imprimez simplement le résultat. Que voyez-vous ?\n","\n","+ Utilisez content() pour obtenir le contenu de resp, mais cette fois, ne spécifiez pas de second argument.\n","\n","+ R comprend automatiquement que vous avez affaire à un JSON, et convertit le JSON en une liste R nommée."],"metadata":{"id":"2Ly3OX8Si6XB"}},{"cell_type":"code","source":["# httr is already loaded\n","\n","# Get the url\n","url <- \"http://www.omdbapi.com/?apikey=72bc447a&t=Annie+Hall&y=&plot=short&r=json\"\n","resp <- GET(url)\n","\n","# Print resp\n","resp\n","\n","# Print content of resp as text\n","content(resp, as = \"text\")\n","\n","# Print content of resp\n","content(resp)"],"metadata":{"id":"K-UdNO6-jMPk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_7bGzOJHflFx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**API et JSON**\n","\n","####**1. API et JSON**\n","+ Dans la partie et les exercices précédents,\n","\n","####**2. Autres formats de données**\n","\n","+ Vous avez vu comment vous pouvez obtenir des fichiers sur le Web. \n","\n","+ Dans le dernier exercice, vous avez également vu qu’il existe également un autre format pour représenter les données, à savoir JSON. \n","\n","+ Le format JSON est très simple, concis et bien structuré. \n","\n","+ En plus de cela, il est lisible par l’homme, mais aussi facile à interpréter et à générer pour les machines. \n","\n","+ Cela le rend parfait pour communiquer avec les API Web.\n","\n","####**3. API**\n","\n","\n","+ **Qu’est-ce qu’une API, je vous entends demander**? Eh bien, c’est l’abréviation de Application Programming Interface. \n","\n","+ Très généralement, **il s’agit d’un ensemble de routines et de protocoles pour la construction de composants logiciels**. \n","\n","+ C’est une façon dont différents composants logiciels interagissent. \n","\n","+ Cela peut se produire de milliers de façons, mais nous nous concentrerons uniquement sur l’API Web. \n","\n","+ En règle générale, il s’agit d’une interface permettant d’obtenir des données et des informations traitées à partir d’un serveur ou d’ajouter des données à un serveur, via les méthodes HTTP que vous avez apprises précédemment.\n","\n","####**4. Twitter (en anglais)**\n","\n","+ À titre d’exemple, prenez Twitter. \n","\n","+ Ils ont également une API, que vous pouvez consulter ici. \n","\n","+ Après l’authentification, vous pouvez simplement demander des URL particulières à **Twitter** avec la requête **GET**, ce qui vous permet d’obtenir les tweets d’une personne en particulier par exemple. \n","\n","+ **Twitter** fait tout le travail pour vous sur leurs serveurs et crache les informations dont vous avez besoin. \n","\n","+ Vous pouvez également utiliser l’API pour placer des commentaires par programmation sur les tweets de quelqu’un, par exemple. \n","\n","+ Les applications possibles sont infinies. \n","\n","+ Disons que vous êtes un tweeter passionné et que vous voulez savoir quels tweets ont eu le plus d’impact. \n","\n","+ Peut-être que certains de vos tweets les plus controversés ont provoqué beaucoup de retweets et de réactions ? \n","\n","+ **Avec les données brutes de l’API de Twitter, vous pouvez faire des recherches à ce sujet**. \n","\n","+ Mais pourquoi les API et JSON sont-ils utiles en premier lieu ? Toutes les informations sont déjà disponibles sur la page Web, non?\n","\n","####**5. Infos sur Rain Man (1988)**\n","\n","+ Eh bien, supposons que vous vouliez obtenir des données sur le film Rain Man, de 1988. \n","\n","+ Vous pouvez télécharger l’URL correspondante d’IMDb, la lire, puis commencer à rechercher par programmation dans le code HTML, qui fait plus de 4000 lignes, pour obtenir les informations dont vous avez besoin. \n","\n","+ C’est assez sujet aux erreurs et vraiment lent. Heureusement, il existe des alternatives. \n","\n","####**6. Rain Man JSON (API OMDb)**\n","\n","+ En l’occurrence, il existe une API appelée l’API OMDb, capable de vous donner des informations sur pratiquement n’importe quel film auquel vous pouvez penser. \n","\n","+ Il suffit d’une URL, avec quelques paramètres supplémentaires tels que l’identifiant du film sur lequel vous souhaitez obtenir des informations et le type de réponse que l’API comprend. \n","\n","+ Si vous visitez simplement cette page Web, vous verrez quelque chose comme ceci. \n","\n","+ Il s’agit d’un JSON, contenant tout ce que nous devons savoir dans un format bien structuré. \n","\n","####**7. JSONLITE**\n","\n","+ Pour convertir ce JSON en une structure de données R, vous pouvez utiliser le paquet jsonlite de Jeroen Ooms. \n","\n","+ Le package est une amélioration des packages R précédents pour gérer les JSON, où la conversion de et vers JSON est plus cohérente et robuste, de sorte qu’elle fonctionne bien dans tous les cas d’utilisation.\n","\n","####**8. Liste Rain Man dans R**\n","\n","+ Installons et chargeons jsonlite, puis appelons simplement à partir de JSON sur l’URL. \n","\n","+ Cela téléchargera les données JSON pour vous et les convertira en une liste R nommée. \n","\n","+ Nous avons maintenant toutes les informations dans R, prêts à faire notre analyse. \n","\n","+ C’est bien mieux que la page HTML désordonnée où nous devrions creuser pour obtenir les éléments d’intérêt, n’est-ce pas?\n","\n","####**9. Entraînons-nous!**\n","+ Je vous suggère de vous diriger vers un peu d’exercice, avant de plonger plus profondément dans le format JSON. Jouir!"],"metadata":{"id":"qvdMCGqV6WtN"}},{"cell_type":"markdown","source":["####**De JSON à R**\n","+ Dans la configuration la plus simple, **fromJSON() peut convertir les chaînes de caractères qui représentent des données JSON en une liste R joliment structurée**. Essayez-le !\n","\n","####**Instructions**\n","\n","+ Chargez le paquet jsonlite. \n","\n","+ wine_json représente un JSON. \n","\n","+ Utilisez fromJSON() pour le convertir en une liste, nommée wine.\n","\n","+ Affichez la structure de wine"],"metadata":{"id":"10k-4B7Q73-r"}},{"cell_type":"code","source":["# Load the jsonlite package\n","library(jsonlite)\n","\n","# wine_json is a JSON\n","wine_json <- '{\"name\":\"Chateau Migraine\", \"year\":1997, \"alcohol_pct\":12.4, \"color\":\"red\", \"awarded\":false}'\n","\n","# Convert wine_json into a list: wine\n","wine <- fromJSON(wine_json)\n","\n","# Print structure of wine\n","str(wine)"],"metadata":{"id":"Y1ln1FTc7mG5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**API Quandl**\n","\n","+ fromJSON() fonctionne également si vous passez une URL sous forme de chaîne de caractères ou le chemin d'accès à un fichier local qui contient des données JSON. \n","\n","+ Essayons cela sur l'API Quandl, où vous pouvez récupérer toutes sortes de données financières et économiques.\n","\n","####**Instructions**\n","\n","+ quandl_url représente une URL. \n","\n","+ Utilisez fromJSON() directement sur cette URL et stockez le résultat dans quandl_data.\n","\n","+ Affichez la structure de quandl_data."],"metadata":{"id":"9MSEkDOP8Oz8"}},{"cell_type":"code","source":["# jsonlite is preloaded\n","\n","# Definition of quandl_url\n","quandl_url <- \"https://www.quandl.com/api/v3/datasets/WIKI/FB/data.json?auth_token=i83asDsiWUUyfoypkgMz\"\n","\n","# Import Quandl data: quandl_data\n","quandl_data <- fromJSON(quandl_url)\n","\n","# Print structure of quandl_data\n","str(quandl_data)"],"metadata":{"id":"qRAi0x0b81Qh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**API OMDb**\n","\n","+ Dans la partie ci-dessus, vous avez vu combien il est facile d'interagir avec une API une fois que vous savez comment formuler des demandes. \n","\n","+ Vous avez également vu comment récupérer toutes les informations sur Rain Man à partir d'OMDb. \n","\n","+ Il suffit d'effectuer un appel GET(), puis de demander le contenu avec la fonction content(). Cette fonction content(), qui fait partie du paquet httr, utilise jsonlite en coulisse pour importer les données JSON dans R.\n","\n","+ Cependant, vous savez maintenant que jsonlite peut gérer les URL lui-même. \n","+ Il suffit de passer l'URL de la requête à fromJSON() pour obtenir vos données dans R. Dans cet exercice, vous utiliserez cette technique pour comparer l'année de sortie de deux films dans l'Open Movie Database.\n","\n","####**Instructions**\n","\n","+ Deux URLs sont incluses dans l'exemple de code, ainsi qu'un appel à fromJSON() pour construire sw4. Ajoutez un appel similaire pour construire sw3.\n","+ Imprimez l'élément nommé Title de sw4 et sw3. Vous pouvez utiliser l'opérateur $. De quels films s'agit-il ici ?\n","+ Écrivez une expression qui donne la valeur TRUE si sw4 est sorti plus tard que sw3. Cette information est stockée dans l'élément Year des listes nommées."],"metadata":{"id":"6y2nNneQ9AzD"}},{"cell_type":"code","source":["# The package jsonlite is already loaded\n","\n","# Definition of the URLs\n","url_sw4 <- \"http://www.omdbapi.com/?apikey=72bc447a&i=tt0076759&r=json\"\n","url_sw3 <- \"http://www.omdbapi.com/?apikey=72bc447a&i=tt0121766&r=json\"\n","\n","# Import two URLs with fromJSON(): sw4 and sw3\n","sw4 <- fromJSON(url_sw4)\n","sw3 <- fromJSON(url_sw3)\n","\n","# Print out the Title element of both lists\n","sw4$Title\n","sw3$Title\n","\n","# Is the release year of sw4 later than sw3?\n","sw4$Year > sw3$Year"],"metadata":{"id":"bHYLCEkk9UU8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**JSON et jsonlite**\n","\n","####**1. JSON et jsonlite**\n","\n","\n","+ Dans cette partie, plongeons dans le format JSON et le paquet jsonlite un peu plus.\n","\n","+  Alors, à quoi ressemble un JSON typique? \n","\n","+ Je vais essayer d’être court sur ce point. Vous avez des objets JSON et vous avez des tableaux JSON.\n","\n","####**2. Objet JSON**\n","\n","+ Un objet JSON typique ressemble à ceci. \n","\n","+ Il s’agit d’une collection non ordonnée de paires nom/valeur. \n","\n","+ où le nom est une chaîne et la valeur peut être une chaîne, un nombre, booléen, null, un autre objet JSON ou un tableau JSON.\n","\n","####**3. Objet JSON**\n","\n","+ Convertissons ce JSON en chaîne R en l’enveloppant entre guillemets. \n","\n","+ J’utilise des guillemets simples ici afin de ne pas avoir à échapper à chaque guillemets doubles. \n","\n","+ Passons maintenant cette chaîne à la fonction JSON de jsonlite, qui convertit un code JSON en code R, et demandons la structure du résultat. \n","\n","+ Le résultat est une liste nommée dans R, qui contient les mêmes informations. Vous pouvez également voir que les éléments ont différentes classes: nous avons des caractères, des entiers et des logiques.\n","\n","####**4. Tableau JSON**\n","\n","+ Ensuite, il existe également des tableaux JSON. Il s’agit d’une séquence ordonnée de valeurs nulles ou plus, comme celle-ci. \n","\n","+ L’appel de JSON sur cette structure JSON génère un vecteur entier. \n","\n","+ Cependant, il s’agit en fait d’une simplification, car les tableaux JSON, tout comme les objets JSON, sont hétérogènes ; Ils peuvent contenir des éléments de différents types. \n","\n","+ Ce tableau JSON, par exemple, est également parfaitement valide. \n","\n","+ En essayant de convertir ce JSON en R, donnez le résultat suivant. \n","+ Les nombres étaient forcés à des caractères, tout comme la valeur logique. \n","+ Le mot-clé null a été converti en NA dans R. Cela a dû être fait parce que les vecteurs R ne peuvent contenir qu’un seul type de base, vous vous souvenez ? \n","+ L’objet JSON et le tableau JSON peuvent contenir d’autres objets et tableaux JSON, comment cela fonctionnerait-il ?\n","\n","####**5. Imbrication JSON**\n","+ Supposons que nous ajoutions des informations à l’objet JSON d’avant. \n","\n","+ Cette fois, j’ai formaté le JSON de manière à ce qu’il devienne plus lisible. Nous pouvons l’étendre comme suit.\n","\n","####**6. Imbrication JSON**\n","+ Faisons ceci, et voyons ce que nous obtenons. \n","+ Nous obtenons une liste nommée imbriquée, c’est parfaitement logique si vous me demandez.\n","\n","####**7. Tableau JSON d’objets JSON**\n","\n","+ Enfin, construisons un tableau d’objets JSON, de trois personnes par exemple, comme ceci. \n","+ Wow, c’était inattendu. Nous avons simplement obtenu un cadre de données. \n","\n","+ Mais si vous y réfléchissez, c’est une excellente cartographie. \n","\n","+ Nous avons trois objets JSON, sur Frank, Julie et Zach, et ils ont tous les mêmes champs, id et name. Cela correspond parfaitement à la description d’une trame de données R. \n","\n","+ Ce qui est merveilleux, c’est que jsonlite s’occupe de tout cela pour nous. \n","\n","+ Il existe de nombreux autres cas d’utilisation d’objets et de tableaux JSON, mais je ne passerai pas en revue chacun d’entre eux. à côté de fromJSON,\n","\n","####**8. Autres fonctions jsonlite**\n","\n","+ Il existe d’autres fonctions utiles dans le package JSONLITE, telles que Tojson, pour reconvertir les structures de données R en **JSON, et Prettify et Minify**, pour modifier la façon dont les JSONS sont affichés. \n","\n","+ Vous apprendrez tout cela dans les exercices qui suivent! Si vous utilisez le paquet jsonlite, vous ne traiterez normalement pas directement avec les JSON, mais il est bon d’avoir un niveau de compréhension de base de ceux-ci.\n","\n","####**9. Entraînons-nous!**"],"metadata":{"id":"XvLJlfLm90eR"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","\n","####**Pratique de JSON (1)**\n","+ JSON est construit sur deux structures : **les objets et les tableaux**. \n","\n","+ Pour vous aider à expérimenter avec celles-ci, deux chaînes JSON sont incluses dans le code d'exemple. \n","\n","+ C'est à vous de les modifier de manière appropriée, puis d'appeler la fonction **fromJSON()** de jsonlite à chaque fois.\n","\n","####**Instructions**\n","\n","+ Modifiez l'affectation de json1 de sorte que le vecteur R après conversion contienne les nombres 1 à 6, dans l'ordre croissant. \n","\n","+ Ensuite, appelez la fonction fromJSON() sur json1.\n","\n","\n","+ Adaptez le code de json2 de sorte qu'il soit converti en une liste nommée avec deux éléments : a, contenant les nombres 1, 2 et 3 et b, contenant les nombres 4, 5 et 6. \n","\n","+ Ensuite, appelez fromJSON() sur json2."],"metadata":{"id":"XP-z0S1I_kfS"}},{"cell_type":"code","source":["# jsonlite is already loaded\n","\n","# Challenge 1\n","json1 <- '[1, 2, 3, 4, 5, 6]'\n","fromJSON(json1)\n","\n","# Challenge 2\n","json2 <- '{\"a\": [1, 2, 3], \"b\": [4, 5, 6]}'\n","fromJSON(json2)"],"metadata":{"id":"dztUKbAc_0Cz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Pratique JSON (2)**\n","\n","+ Nous avons préparé deux chaînes JSON supplémentaires dans l'exemple de code.\n","\n","+ Pouvez-vous les modifier et appeler **la fonction fromJSON()** de jsonlite sur elles, comme dans l'exercice précédent ?\n","\n","####**Instructions**\n","\n","+ Enlevez les caractères de json1 pour construire une matrice 2 par 2 contenant seulement 1, 2, 3 et 4. Appelez la fonction fromJSON() sur json1.\n","\n","+ Ajoutez des caractères à json2 de sorte que le cadre de données dans lequel le json est converti contienne une observation supplémentaire dans la dernière ligne. \n","\n","+ Pour cette observation, a est égal à 5 et b est égal à 6. Appelez fromJSON() une dernière fois, sur json2."],"metadata":{"id":"Fe0AVzvGAQdb"}},{"cell_type":"code","source":["# jsonlite is already loaded\n","\n","# Challenge 1\n","json1 <- '[[1, 2], [3, 4], [5, 6]]'\n","fromJSON(json1)\n","\n","# Challenge 2\n","json2 <- '[{\"a\": 1, \"b\": 2}, {\"a\": 3, \"b\": 4}, {\"a\": 5, \"b\": 6}]'\n","fromJSON(json2)"],"metadata":{"id":"Kl8gUKL29Ufx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**toJSON()**\n","\n","\n","+ Outre la conversion de JSON en R avec **fromJSON()**, vous pouvez également utiliser **toJSON()** pour convertir des données R au format **JSON**. \n","\n","+ Dans son utilisation la plus basique, vous passez simplement à cette fonction un objet R à convertir en JSON. \n","+ Le résultat est un objet R de la classe json, qui est en fait une chaîne de caractères représentant ce JSON.\n","\n","+ Pour cet exercice, vous allez travailler avec un fichier .csv contenant des informations sur la quantité d'eau dessalée produite dans le monde. \n","\n","+ Comme vous le verrez, il contient beaucoup de valeurs manquantes. Ces données peuvent être trouvées sur l'URL qui est spécifié dans l'exemple de code.\n","\n","####**Instructions**\n","\n","+ Utilisez une fonction du paquet utils pour importer le fichier .csv directement depuis l'URL spécifié dans url_csv. \n","\n","+ Enregistrez le cadre de données résultant comme water. \n","\n","+ Assurez-vous que les chaînes de caractères ne sont pas importées comme facteurs.\n","\n","+ Convertissez le cadre de données water en JSON. \n","\n","+ Appelez l'objet résultant water_json.\n","Imprimez water_json."],"metadata":{"id":"4gaWWV_JAs2A"}},{"cell_type":"code","source":["# jsonlite is already loaded\n","\n","# URL pointing to the .csv file\n","url_csv <- \"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/water.csv\"\n","\n","# Import the .csv file located at url_csv\n","water <- read.csv(url_csv, stringsAsFactors = FALSE)\n","\n","# Convert the data file according to the requirements\n","water_json <- toJSON(water)\n","\n","# Print out water_json\n","water_json"],"metadata":{"id":"Y6RchaxHBA-7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Réduire et simplifier**\n","+ Les JSON peuvent se présenter sous différents formats. \n","+ Prenez ces deux JSON, qui sont en fait exactement les mêmes : le premier est dans un format miniaturisé, le second est dans un joli format avec indentation, espaces et nouvelles lignes :\n","\n","        # Mini\n","      {\"a\":1,\"b\":2,\"c\":{\"x\":5,\"y\":6}}\n","\n","      # Pretty\n","      {\n","        \"a\" : 1,\n","        \"b\" : 2,\n","        \"c\" : {\n","        \"x\" : 5,\n","        \"y\" : 6\n","      }\n","    }\n","\n","+ À moins que vous ne soyez un ordinateur, vous préférez sûrement la deuxième version. \n","\n","+ Cependant, la forme standard que **toJSON()** renvoie est la version minifiée, car elle est plus concise. \n","\n","+ Vous pouvez adapter ce comportement en donnant la valeur TRUE à l'argument pretty dans **toJSON()**. \n","\n","+ Si vous avez déjà une chaîne JSON, vous pouvez utiliser **prettify() ou minify()** pour rendre le JSON joli ou aussi concis que possible.\n","\n","####**Instructions**\n","\n","+ Convertissez l'ensemble de données mtcars, qui est disponible dans R par défaut, en un joli JSON. \n","+ Appelez le JSON résultant pretty_json.\n","\n","+ Imprimez pretty_json. Pouvez-vous comprendre la sortie facilement ?\n","\n","+ Convertissez pretty_json en une version minimale en utilisant minify(). \n","+ Stockez cette version dans une nouvelle variable, mini_json.\n","\n","+ Imprimez mini_json. \n","\n","+ Quelle version préférez-vous, la jolie version ou la version minifiée ?"],"metadata":{"id":"5Te4oB0mBk-k"}},{"cell_type":"code","source":["# jsonlite is already loaded\n","\n","# Convert mtcars to a pretty JSON: pretty_json\n","pretty_json <- toJSON(mtcars, pretty = TRUE)\n","\n","# Print pretty_json\n","pretty_json\n","\n","# Minify pretty_json: mini_json\n","mini_json <- minify(pretty_json)\n","\n","# Print mini_json\n","mini_json"],"metadata":{"id":"-tmHgDvzCBtK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Havre de paix**\n","\n","####**1. Havre de paix**\n","+ Une chose dont nous n’avons pas encore discuté, ce sont les données provenant d’autres\n","\n","####**2. Progiciels statistiques**\n","+ progiciels statistiques. Le plus commun\n","\n","####**3. Progiciels statistiques**\n","\n","+ les uns sont SAS, abréviation de Statistical **Analysis Software, STATA, qui signifie statistiques et données, et SPSS, ou le progiciel statistique pour les sciences sociales**. \n","+ Le logiciel que les gens utilisent dépend du domaine d’études ou de ses préférences personnelles.\n","\n","####**4. Progiciels statistiques**\n","\n","+ SAS, par exemple, est l’un des outils logiciels d’analyse commerciale les plus répandus et est également couramment utilisé en biostatistique ou en sciences médicales. \n","\n","+ D’autre part, STATA est un outil typique pour les économistes. SPSS est souvent utilisé en sciences sociales, d’où son nom.\n","\n","####**5. Progiciels statistiques**\n","+ En fin de compte, chaque logiciel utilise et produit ses propres types de fichiers. \n","+ Les extensions les plus courantes sont répertoriées ici.\n","\n","####**6. Packages R pour importer des données**\n","\n","+ Quel que soit le package d’où proviennent vos données, R est préparé pour chaque fichier qui arrivera ! \n","\n","+ Dans la suite de ce chapitre, vous apprendrez à utiliser deux packages R qui peuvent importer des données à partir de ces environnements logiciels : **haven et foreign**. \n","\n","+ Le premier est écrit par Hadley Wickham, l’autre par l’équipe principale de R. \n","\n","+ Le paquet étranger existe depuis plus longtemps, tandis que le havre est toujours en développement aujourd’hui, à la fin de 2015. \n","\n","+ Wickham vise à fournir une alternative plus cohérente, plus facile à utiliser et plus rapide à l’étranger. \n","\n","+ D’autre part, étranger prend en charge plus de formats de données. Mais ne tirons pas de conclusions hâtives ici. \n","\n","+ Dans cette vidéo, je parlerai un peu plus de refuge, et dans la prochaine partie, je parlerai de l’étranger. Après cela, vous pouvez choisir vous-même le forfait que vous préférez.\n","\n","####**7. Havre de paix**\n","\n","+ Donc, le paquet refuge. \n","\n","+ Ce paquet peut traiter les fichiers de données **SAS, STATA et SPSS**. \n","\n","+ Pour ce faire, il s’enroule autour de la bibliothèque ReadStat C d’Evan Miller.\n","\n","+ Tout comme readr et readxl, le package est extrêmement simple à utiliser. \n","\n","+ Vous passez le chemin d’accès au fichier de données et un bloc de données R en résulte. \n","\n","+ Après avoir installé haven avec install-dot-packages, vous pouvez le charger avec la fonction bibliothèque.\n","\n","####**8. Données SAS**\n","\n","+ Commençons par charger un fichier de données SAS. \n","\n","+ Supposons que vous ayez un fichier, 'ontime dot sas7bdat' dans votre répertoire de travail actuel. \n","\n","+ Il contient des données sur le pourcentage de vols arrivés à l’heure pour plusieurs compagnies aériennes aux États-Unis. \n","\n","+ Pour importer ces données en tant que trame de données à temps, il vous suffit d’utiliser la fonction read_sas et de passer le chemin d’accès au fichier de données :\n","\n","####**9. Données SAS**\n","\n","+ Si vous imprimez sa structure, vous verrez que chaque variable du bloc de données possède également un attribut label. \n","\n","+ Si vous connaissez SAS, vous savez que vous pouvez étiqueter des variables dans des jeux de données SAS. Eh bien, ce sont ces mêmes étiquettes qui sont également disponibles dans R maintenant.\n","\n","####**10. Données SAS**\n","\n","+ Lorsque vous imprimez simplement à temps, vous ne voyez aucune différence avec une trame de données normale sans étiquettes.\n","\n","####**11. Données SAS**\n","+ Si vous utilisez la fonction View de RStudio pour explorer un jeu de données, cependant,\n","\n","####**12. Données SAS**\n","+ Vous verrez les étiquettes : Pouvez-vous lire les données ici? En mars 1999, par exemple,\n","\n","####**13. Données SAS**\n","+ il semble qu’environ 79% de tous les vols de Delta Airline étaient à l’heure.\n","\n","####**14. REÇU**\n","+ La prochaine étape est STATA. \n","\n","+ Haven est capable d’importer des fichiers Stata 13 et 14 avec la fonction read_stata. \n","\n","+ Vous pouvez également utiliser read_dta, qui fait exactement la même chose.\n","\n","####**15. REÇU**\n","\n","+ Tout comme avant, il suffit de passer le chemin d’accès au fichier dot dta fera l’affaire. \n","+ Supposons que les mêmes statistiques sur les compagnies aériennes américaines soient maintenant disponibles sous forme de fichier dot dta, ontime dot dta, qui se trouve dans votre répertoire de travail actuel, vous pouvez essayer l’un ou l’autre de ces appels. \n","+ L’impression semble à nouveau assez familière, mais il y a quelque chose de différent ici. \n","\n","+ Les noms des compagnies aériennes sont convertis en nombres, ce ne sont plus des chaînes de caractères. Comment en est-on arrivé là?\n","\n","####**16. REÇU**\n","\n","+ Si vous jetez un coup d’œil à la classe de la colonne Compagnie aérienne de ontime, elle semble être de classe étiquetée. \n","\n","+ Il s’agit de la version R du vecteur marqué, une structure de données commune dans d’autres progiciels statistiques. \n","\n","+ Si vous imprimez simplement cette colonne Compagnie aérienne, vous pouvez voir les noms des compagnies aériennes d’avant. R numéros attribués à chaque variable selon leur ordre alphabétique. \n","\n","+ Comme vous souhaitez poursuivre votre analyse dans R, il est judicieux de convertir ce vecteur en une classe R standard, telle qu’un facteur.\n","\n","####**17. as_factor ()**\n","\n","+ Au lieu de la fonction standard en tant que facteur de points, de la base R, vous aurez besoin de « haven » comme facteur de soulignement pour cela. \n","+ C’est le type de variables catégorielles auxquelles nous sommes habitués. \n","+ Dans ce cas, il serait peut-être encore mieux d’avoir des caractères simples pour les noms des compagnies aériennes, car ce ne sont pas vraiment des catégories. \n","+ La fonction de base R en tant que caractère de point peut le faire pour vous. Plaçons-le simplement autour de l’appel précédent.\n","\n","####**18. as_factor ()**\n","+ Si vous affectez à nouveau ce résultat à la colonne Airline de ontime, vous avez préparé la trame de données ontime pour une analyse plus approfondie, avec les noms sous forme de simples chaînes de caractères.\n","\n","####**19. Données SPSS**\n","\n","+ Enfin et surtout, il existe des données SPSS. \n","\n","+ Ici, vous voudrez utiliser read_spss. Sur la base de l’extension, haven décidera pour vous quelle fonction appeler: read_por pour les fichiers dot por ou read_sav pour les fichiers dot sav. \n","\n","+ Chargeons une fois de plus les données de la compagnie aérienne, qui sont stockées sous forme de fichier point sav dans le dossier des jeux de données de notre répertoire personnel. \n","+ Encore une fois, un bloc de données en résulte. \n","+ La colonne Compagnie aérienne est à nouveau un vecteur étiqueté. Les noms de colonne ici sont légèrement différents de ceux d’avant.\n","\n","####**20. Progiciels statistiques**\n","\n","+ Cela devrait être clair maintenant: haven est incroyablement facile à utiliser et fait simplement ce qu’il est censé faire. \n","+ Jetez un coup d’œil au résumé ici, maintenant avec les fonctions correspondantes.\n","\n","####**21. Entraînons-nous!**\n","+ Maintenant, allez-y et entraînez-vous!"],"metadata":{"id":"r5P42E3tHUvT"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","####**Importer des données SAS avec haven**\n","\n","+ haven est un logiciel extrêmement facile à utiliser pour importer des données à partir de trois progiciels : SAS, STATA et SPSS. \n","+ Selon le logiciel, vous utilisez des fonctions différentes :\n","\n","  + SAS : **read_sas()**\n","  + STATA : **read_dta() (ou read_stata(), qui sont identiques)**\n","  + SPSS : **read_sav() ou read_por()**, selon le type de fichier.\n","\n","+ Toutes ces fonctions prennent un argument clé : le chemin d'accès à votre fichier local. \n","+ En fait, vous pouvez même passer une URL ; haven téléchargera alors automatiquement le fichier pour vous avant de l'importer.\n","\n","+ Vous allez travailler avec des données sur l'âge, le sexe, le revenu et le niveau d'achat (0 = faible, 1 = élevé) de 36 personnes (Source : SAS). \n","\n","+ Les informations sont stockées dans un fichier SAS, sales.sas7bdat, qui est disponible dans votre répertoire de travail actuel. Vous pouvez également télécharger les données ici.\n","\n","####**Instructions**\n","\n","+ Chargez le paquet haven.\n","\n","+ Importez le fichier de données \"sales.sas7bdat\". Appelez le cadre de données importé \"sales\".\n","\n","+ Affichez la structure de sales avec str(). \n","\n","+ Certaines colonnes représentent des variables catégorielles, elles doivent donc être des facteurs."],"metadata":{"id":"NKn2-Y5oJRVp"}},{"cell_type":"code","source":["# Load the haven package\n","library(haven)\n","\n","# Import sales.sas7bdat: sales\n","sales <- read_sas(\"sales.sas7bdat\")\n","\n","# Display the structure of sales\n","str(sales)"],"metadata":{"id":"9BPLP4quI-Es"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Importer des données STATA avec haven**\n","\n","+ Ensuite, il y a les fichiers de données STATA ; vous pouvez utiliser read_dta() pour ceux-ci.\n","\n","+ En inspectant le résultat de l'appel read_dta(), vous remarquerez qu'une colonne sera importée en tant que vecteur étiqueté, un équivalent R de la structure de données courante dans d'autres environnements statistiques. \n","\n","+ Afin de continuer à travailler efficacement sur les données dans R, il est préférable de transformer ces données en une classe R standard. \n","\n","+ Pour convertir une variable de la classe étiquetée en un facteur, vous aurez besoin de **la fonction as_factor() de haven**.\n","\n","+ Dans cet exercice, vous allez travailler avec des données sur les chiffres annuels d'importation et d'exportation de sucre, à la fois en USD et en poids. \n","\n","+ Les données sont disponibles à l'adresse suivante : \n","\n","  + http://assets.datacamp.com/production/course_1478/datasets/trade.dta\n","\n","####**Instructions**\n","\n","+ Importez le fichier de données directement depuis l'URL en utilisant **read_dta()**, et stockez-le sous forme de sucre.\n","\n","+ Imprimez la structure du sucre. La colonne Date a une classe étiquetée.\n","\n","+ Convertissez les valeurs de la colonne Date de sugar en dates, en utilisant **as.Date(as_factor(___))**.\n","\n","+ Imprimez une nouvelle fois la structure de Sugar. C'est mieux maintenant ?"],"metadata":{"id":"FHD2_ksKJ_xx"}},{"cell_type":"code","source":["# haven is already loaded\n","\n","\n","# Import the data from the URL: sugar\n","sugar <- read_dta(\"http://assets.datacamp.com/production/course_1478/datasets/trade.dta\")\n","\n","# Structure of sugar\n","str(sugar)\n","\n","\n","# Convert values in Date column to dates\n","sugar$Date <- as.Date(as_factor(sugar$Date))\n","\n","# Structure of sugar again\n","str(sugar)"],"metadata":{"id":"6KLU-F07KUOk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Que dit le graphique ?**\n","\n","+ Un graphique peut être très utile pour explorer la relation entre deux variables. \n","\n","+ Si vous passez deux arguments à la fonction plot(), le premier sera tracé sur l'axe des $x$, le second sur l'axe des $y$.\n","\n","+ Les données relatives au commerce du sucre sont à nouveau disponibles sur:\n","  + http://assets.datacamp.com/production/course_1478/datasets/trade.dta.\n","\n","+ Après avoir importé le cadre de données, vous devez tracer deux de ses variables, Import et Weight_I, et décrire leur relation ! \n","+ haven est déjà chargé dans votre session R, vous pouvez donc commencer à importer directement.\n","\n","####**Instructions**\n","\n","\n","+ La relation entre les chiffres d'importation en USD et les chiffres d'importation en poids peut être décrite par une fonction quadratique qui a un maximum local.\n","\n","+ **Les chiffres d'importation en USD et les chiffres d'importation en poids sont plutôt positivement corrélés**.\n","\n","+ Les chiffres d'importation en USD et les chiffres d'importation en poids sont négativement associés. Le long des points, on observe une tendance monotone décroissante.\n","\n","+ Aucune relation ne peut être devinée entre le poids et la valeur du sucre importé."],"metadata":{"id":"Kfh3jQ74KqtA"}},{"cell_type":"markdown","source":["####**Importer des données SPSS avec haven**\n","\n","+ Le package haven peut également importer des fichiers de données à partir de SPSS. Là encore, l'importation des données est assez simple. \n","\n","+ Selon le fichier de données SPSS avec lequel vous travaillez, vous aurez besoin soit de read_sav() - pour les fichiers .sav - soit de read_por() - pour les fichiers .por.\n","\n","+ Dans cet exercice, vous allez travailler avec des données sur quatre des cinq grands traits de personnalité pour 434 personnes (Source : Université de Bath). \n","+ Le Big Five est un concept psychologique comprenant, à l'origine, cinq dimensions de la personnalité pour classifier la personnalité humaine. Le jeu de données SPSS s'appelle person.sav et est disponible dans votre répertoire de travail.\n","\n","####**Instructions**\n","\n","+ Utilisez read_sav() pour importer les données SPSS dans \"person.sav\". Nommez le cadre de données importé traits contient plusieurs valeurs manquantes, ou NAs. \n","\n","+ Exécutez summary() pour savoir combien de valeurs manquantes sont contenues dans chaque variable.\n","\n","+ Imprimez un sous-ensemble des individus qui ont obtenu un score élevé en matière d'extraversion et d'agréabilité, c'est-à-dire un score supérieur à 40 dans chacune de ces deux catégories. Vous pouvez utiliser subset() pour cela."],"metadata":{"id":"5iojxxLdLbao"}},{"cell_type":"code","source":["# haven is already loaded\n","\n","# Import person.sav: traits\n","traits <- read_sav(\"person.sav\")\n","\n","# Summarize traits\n","summary(traits)\n","\n","# Print out a subset\n","subset(traits, Extroversion > 40 & Agreeableness > 40)"],"metadata":{"id":"54aV9QEIJpPh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Factorisation, deuxième round**\n","+ Dans le dernier exercice, vous avez appris à importer un fichier de données à l'aide de la commande **read_sav()**. \n","\n","+ Avec les fichiers de données SPSS, il peut arriver que certaines des variables que vous importez aient la classe étiquetée. \n","\n","+ Ceci est fait pour conserver toutes les informations d'étiquetage qui étaient initialement présentes dans les fichiers .sav et .por. \n","\n","+ Il est conseillé de contraindre (ou de changer) ces variables en facteurs ou autres classes R standard.\n","\n","+ Les données pour cet exercice sont des informations sur les employés et leurs attributs démographiques et économiques (Source : QRiE). \n","+ Les données peuvent être trouvées sur l'URL suivant :\n","\n","  + http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/employee.sav\n","\n","####**instructions**\n","\n","+ Importez les données SPSS directement depuis l'URL et stockez le cadre de données résultant en tant que travail.\n","\n","+ Affichez le résumé de la colonne GENDER de work. \n","\n","+ Cette information ne vous donne pas beaucoup d'informations utiles, n'est-ce pas ?\n","\n","\n","+ Convertissez la colonne GENDER de work en un facteur, la classe pour désigner les variables catégorielles dans R. Utilisez as_factor().\n","\n","+ Affichez à nouveau le résumé de la colonne GENDER. Cette fois, l'impression est beaucoup plus logique."],"metadata":{"id":"P66vQbE7MNYI"}},{"cell_type":"code","source":["# haven is already loaded\n","\n","# Import SPSS data from the URL: work\n","work <- read_sav(\"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/employee.sav\")\n","\n","# Display summary of work$GENDER\n","summary(work$GENDER)\n","\n","# Convert work$GENDER to a factor\n","work$GENDER <- as_factor(work$GENDER)\n","\n","# Display summary of work$GENDER again\n","summary(work$GENDER)"],"metadata":{"id":"tnEbzwBoMgUw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**étranger**\n","\n","####**1.étranger**\n","\n","+ Vous savez déjà comment importer vos données en utilisant le package haven de Wickham, génial!\n","\n","####**2. Étranger**\n","\n","+ Cependant, je vous ai également dit qu’il existe une autre alternative, le paquet étranger, écrit par l’équipe de base R. \n","\n","+ Bien qu’il soit un peu moins cohérent dans la dénomination et l’utilisation, c’est un outil très complet qui peut fonctionner avec toutes sortes de formats de données étrangers. \n","\n","+ Outre l’importation de fichiers SAS, STATA et SPSS, il peut également gérer des formats encore plus exotiques, de Systat et Weka par exemple. \n","\n","+ Il est également capable d’exporter à nouveau des données vers différents formats. \n","\n","+ Je ne parlerai que de l’importation de données **SAS, STATA et SPSS**. \n","\n","+ Avant d’y arriver, laissez-moi installer et charger le paquet étranger.\n","\n","####**3. SAS**\n","\n","+ Commençons d’abord par SAS. \n","\n","+ Eh bien, ici le premier inconvénient de l’étranger par rapport au havre émerge. \n","\n","+ Les étrangers ne peuvent pas importer de fichiers de données SAS uniques, tels que les fichiers point sas7bdat. \n","\n","+ Avec l’étranger, seules les bibliothèques dites SAS peuvent être lues. Ces bibliothèques sont généralement au format point-xport. \n","\n","+ Si vous cherchez vraiment une alternative au paradis ici, vous pouvez consulter un package appelé sas7bdat.\n","\n","####**4. STATA**\n","\n","+ En ce qui concerne STATA, l’étranger peut être utilisé pour lire les fichiers dot dta des versions 5 à 12 de Stata aujourd’hui. \n","\n","+ Vous pouvez le faire avec la fonction read dot dta. \n","\n","+ Comme vous l’avez vu précédemment, les paquets de l’équipe de base R tels que utils et ce paquet étranger, utilisent des points dans leurs noms de fonction, tandis que les paquets de Wickham utilisent des traits de soulignement. \n","\n","+ Jetez un coup d’œil à cette utilisation simplifiée de la fonction read dot dta. \n","\n","+ Comme vous vous y attendiez probablement, vous devez d’abord définir un chemin de fichier. Il peut s’agir d’un fichier local ou d’une URL.\n","\n","####**5. read.dta()**\n","\n","+ Fondamentalement, cela est déjà suffisant pour importer un ensemble de données, comme le montre cet appel à importer l’ensemble de données de ponctualité des compagnies aériennes américaines.\n","\n","####**6. read.dta()**\n","+ Jetez un coup d’œil à la structure de ce cadre de données. \n","+ La variable Compagnie aérienne est déjà un facteur. \n","+ En effet, l’argument convert dot factors de la fonction read dot dta est TRUE par défaut. \n","+ Cela crée ensuite automatiquement des facteurs à partir des valeurs STATA étiquetées. \n","+ C’est quelque chose que vous deviez faire manuellement dans le paquet de paradis avec as_factor, vous vous souvenez?\n","\n","####**7. read.dta() - convert.factors**\n","\n","+ Voyons ce qui se passe si nous définissons les facteurs de conversion des points en FAUX. \n","\n","+ La colonne Airline est maintenant entière. Ces informations sur les compagnies aériennes sont-elles perdues alors? Pas du tout. \n","\n","+ Notez toutes les informations stockées dans les attributs du bloc de données. \n","\n","+ D’après l’attribut version, par exemple, vous pouvez dire que nous avons affaire à un fichier STATA 7. \n","\n","+ L’attribut label dot table contient un mappage entre les codes de compagnie aérienne entiers et leurs noms réels. \n","\n","+ Pour travailler facilement avec le jeu de données, vous voudrez vous en tenir à l’argument par défaut de convertir les facteurs de points, ce qui est TRUE.\n","\n","####**8. read.dta() - plus d’arguments**\n","\n","+ Comme pour convertir les facteurs de points, il existe également des dates de conversion de points pour spécifier si vous souhaitez que les informations d’heure et de date STATA soient converties en objets R Date et POSIXct. \n","\n","+ Comme c’est quelque chose que vous voudrez généralement faire, les valeurs par défaut ici sont TRUE. \n","\n","+ Enfin, je voulais également mentionner l’argument du type point manquant. Si vous êtes familier avec STATA 8 et les versions ultérieures, vous saurez qu’il existe un support pour différents types de valeurs manquantes, 27 d’entre elles pour être précis. \n","\n","+ Dans R, il n’y a qu’un seul type de valeurs manquantes, NA. \n","\n","+ Si vous définissez l’argument type manquant sur FALSE, toutes ces différentes valeurs manquantes sont converties en NA. \n","\n","+ S’il est défini sur TRUE, une liste contenant des informations sur la façon dont différentes valeurs pour différentes variables sont manquantes est incluse dans les attributs de la trame de données renvoyée.\n","\n","####**9. SPSS**\n","\n","+ L’importation de fichiers SPSS avec des fichiers étrangers fonctionne de la même manière. \n","+ Cette fois, cependant, vous aurez besoin de la fonction read dot spss. \n","\n","+ Pas très surprenant n’est-ce pas? Jetez un autre coup d’œil à une version réduite de son utilisation. Comme d’habitude, le chemin du fichier vient en premier. \n","\n","+ Pour le reste, tous les noms d’arguments sont différents lorsque vous comparez à la fonction dta de lecture d’avant. \n","\n","+ C’est ce que je voulais dire par pas vraiment cohérent avant 'use dot value dot labels', qui est TRUE par défaut, spécifie si les variables qui sont étiquetées vecteurs dans SPSS doivent être converties en facteurs R. \n","\n","+ Cet argument est donc similaire à l’argument de conversion du facteur de point à partir des données lues. \n","\n","+ L’argument 'to dot data dot frame' indique à R s’il doit ou non renvoyer les données SPSS en tant que trame de données. \n","\n","+ Étrangement, c’est FALSE par défaut, ce qui permet à l’étranger de construire une liste contenant toutes les différentes colonnes. \n","\n","+ Mais vous savez déjà qu’une trame de données est simplement un type spécial de liste, donc la différence n’est pas si grande. \n","\n","+ À côté de ces deux arguments, il y en a beaucoup d’autres, tels que les noms de facteurs de coupe, les valeurs de coupe et les absences d’utilisation. \n","\n","+ Leur objectif est souvent similaire à ce que vous avez vu pour la fonction read dot dta, mais pas toujours. \n","\n","+ L’étranger vise un traitement spécifique des différents types de fichiers de données. \n","\n","+ Cela n’améliore pas la cohérence, mais fournit un contrôle total sur la façon dont les fichiers de données sont réellement importés. \n","\n","+ Pour en savoir plus sur l’importation de données avec des données étrangères, vous pouvez toujours consulter la documentation. Mais gardez cela pour plus tard,\n","\n","####**10. Entraînons-nous!***\n","+ Dirigez-vous d’abord vers les exercices interactifs pour vous entraîner. Vous y verrez comment différents arguments influencent la façon dont les données sont importées."],"metadata":{"id":"kzstLACDMy7T"}},{"cell_type":"markdown","source":["###**EXERCICE**\n","+ https://results.elections.myflorida.com/\n","\n","####**Importer des données STATA avec foreign (1)**\n","\n","+ Le paquetage foreign offre une fonction simple pour importer et lire des données STATA : read.dta().\n","\n","+ Dans cet exercice, vous allez importer des données sur les élections présidentielles américaines de l'année 2000. \n","+ Les données dans florida.dta contiennent le nombre total de votes pour chacun des quatre candidats ainsi que le nombre total de votes par zone électorale dans l'état de Floride (Source : Florida Department of State). \n","+ Le fichier est disponible dans votre répertoire de travail, vous pouvez le télécharger ici si vous voulez expérimenter un peu plus.\n","\n","####**Instructions**\n","\n","+ Chargez le paquet étranger.\n","\n","+ Importez les données sur les élections en Floride, \"florida.dta\", et nommez le cadre de données résultant florida. \n","+ Utilisez read.dta() sans spécifier d'arguments supplémentaires.\n","+ Vérifiez les 6 dernières observations de florida avec tail()"],"metadata":{"id":"d27Rk6J7OPO3"}},{"cell_type":"code","source":["# Load the foreign package\n","library(foreign)\n","\n","# Import florida.dta and name the resulting data frame florida\n","florida <- read.dta(\"florida.dta\")\n","\n","# Check tail() of florida\n","tail(florida)"],"metadata":{"id":"-SVUEjA2Oeug"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Importer des données STATA avec foreign (2)**\n","+ https://genderdata.worldbank.org/\n","+ Les données peuvent être très diverses, allant des vecteurs de caractères aux variables catégorielles, aux dates et plus encore. \n","+ C'est dans ces cas que les arguments supplémentaires de **read.dta()** seront utiles.\n","\n","+ Les arguments que vous utiliserez le plus souvent sont convert.dates, convert.factors, missing.type et convert.underscore. \n","\n","+ Leur signification est assez simple, comme l'explique Filip. \n","\n","+ Il s'agit de convertir correctement les données STATA en structures de données R standard. \n","\n","+ Tapez ?read.dta pour en savoir plus sur les valeurs par défaut.\n","\n","+ Le jeu de données pour cet exercice contient des mesures socio-économiques et l'accès à l'éducation pour différents individus (Source : Banque Mondiale). \n","\n","+ Ces données sont disponibles sous le nom de edequality.dta, qui se trouve dans le dossier worldbank de votre répertoire de travail.\n","\n","####**Instructions**\n","\n","+ Spécifiez le chemin d'accès au fichier en utilisant file.path(). \n","\n","+ Appelez-le path. \n","\n","+ Rappelez-vous que le fichier \"edequality.dta\" est situé dans le dossier \"worldbank\".\n","\n","\n","+ Utilisez la variable path pour importer le fichier de données de trois manières différentes ; à chaque fois, montrez sa structure avec str() :\n","  + edu_equal_1 : En passant uniquement le chemin du fichier à read.dta().\n","  + edu_equal_2 : En passant le chemin du fichier, et en mettant convert.factors à FALSE.\n","  + edu_equal_3 : En passant le chemin du fichier, et en mettant convert.underscore à TRUE."],"metadata":{"id":"zHp9WM3WO_f5"}},{"cell_type":"code","source":["# foreign is already loaded\n","\n","# Specify the file path using file.path(): path\n","path <- file.path(\"worldbank\", \"edequality.dta\")\n","\n","# Create and print structure of edu_equal_1\n","edu_equal_1 <- read.dta(path)\n","str(edu_equal_1)\n","\n","\n","# Create and print structure of edu_equal_2\n","edu_equal_2 <- read.dta(path, convert.factors = FALSE)\n","str(edu_equal_2)\n","\n","\n","# Create and print structure of edu_equal_3\n","edu_equal_3 <- read.dta(path, convert.underscore = TRUE)\n","str(edu_equal_3)"],"metadata":{"id":"2M-Rrya0OFep"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Connaissez-vous vos données ?**\n","\n","+ L'exercice précédent portait sur les indicateurs socio-économiques et l'accès à l'éducation de différents individus. \n","\n","+ L'ensemble de données edu_equal_1 que vous avez construit est déjà disponible dans l'espace de travail. \n","\n","+ Maintenant que vous l'avez dans R, il est assez facile d'obtenir quelques informations de base.\n","\n","+ Par exemple, vous pouvez vous demander combien d'observations (par exemple, combien de personnes) ont un âge supérieur à 40 ans et sont alphabétisées ? Lorsque vous appelez\n","\n","        str(edu_equal_1)\n","\n","+ vous verrez que l'âge est un nombre entier et que le fait de savoir lire et écrire est un facteur, avec les niveaux \"oui\" et \"non\". \n","\n","+ L'expression suivante répond donc à la question :\n","\n","      nrow(subset(edu_equal_1, age > 40 & literate == \"yes\"))\n","\n","+ À vous de répondre maintenant à une question similaire :\n","\n","+ Combien d'observations/individus d'ethnie bulgare ont un revenu supérieur à 1000 ?\n","\n","####**Instructions**\n","\n","+ 9457\n","\n","+ **1000**\n","\n","+ 8997\n","\n","+ 10840"],"metadata":{"id":"loEenVALQCaY"}},{"cell_type":"markdown","source":["####**Importer des données SPSS avec foreign (1)**\n","\n","+ Toutes les bonnes choses vont par paire. Là où foreign fournit read.dta() pour lire les données Stata, il y a aussi read.spss() pour lire les fichiers de données SPSS. \n","\n","+ Pour obtenir un cadre de données, assurez-vous de définir to.data.frame = TRUE dans read.spss().\n","\n","+ Dans cet exercice, vous allez travailler avec des variables socio-économiques de différents pays (Source : Quantative Data Analysis in Education). \n","\n","+ Les données SPSS se trouvent dans un fichier appelé international.sav, qui se trouve dans votre répertoire de travail. \n","\n","+ Vous pouvez également le télécharger ici si vous voulez jouer avec un peu plus.\n","\n","####**Instructions**\n","\n","+ Importez le fichier de données \"international.sav\" et demandez à R de le convertir en un cadre de données. Stockez ce cadre de données en tant que demo.\n","+ Créez un boxplot de la variable gdp de demo."],"metadata":{"id":"bwrF0SUtQac1"}},{"cell_type":"code","source":["# foreign is already loaded\n","\n","# Import international.sav as a data frame: demo\n","demo <- read.spss(\"international.sav\", to.data.frame = TRUE)\n","\n","# Create boxplot of gdp variable of demo\n","boxplot(demo$gdp)"],"metadata":{"id":"OwNstE5yOGDi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####**Excursion : Corrélation**\n","\n","+ Si vous êtes familier avec les statistiques, vous avez certainement entendu parler de la corrélation de Pearson. \n","\n","+ Il s'agit d'une mesure permettant d'évaluer la dépendance linéaire entre deux variables, disons $X$ et $Y$. \n","\n","+ Elle peut varier de -1 à 1. Si elle est proche de 1, cela signifie qu'il existe une forte association positive entre les variables. \n","\n","+ S'il est élevé, il a également tendance à être élevé. S'il est proche de -1, il existe une forte association négative : Si est élevé, tend à être faible. \n","\n","+ Lorsque la corrélation de Pearson entre deux variables est égale à 0, ces variables sont probablement indépendantes : il n'y a pas d'association entre et .\n","\n","+ Vous pouvez calculer la corrélation entre deux vecteurs avec la fonction cor(). \n","+ Prenez par exemple ce code qui calcule la corrélation entre les colonnes hauteur et largeur d'un cadre de données fictif taille :\n","\n","      cor(size$height, size$width)\n","\n","+ Les données avec lesquelles vous avez travaillé dans l'exercice précédent, international.sav, sont à nouveau disponibles dans votre répertoire de travail. \n","\n","+ Il s'agit maintenant de les importer et d'effectuer les calculs corrects pour répondre à la question suivante :\n","\n","+ Quel est le coefficient de corrélation des deux variables numériques gdp et f_illit (taux d'analphabétisme féminin) ?\n","\n","####**Instructions**\n","\n","\n","+ La corrélation est très proche de 0. Par conséquent, il n'existe aucune association entre l'analphabétisme féminin et le PIB pour l'ensemble de données utilisé.\n","\n","+ **La corrélation est d'environ -0,45. Il existe une corrélation négative, mais elle est plutôt faible**.\n","\n","+ La corrélation est presque égale à +1. Le PIB et l'analphabétisme féminin sont presque parfaitement corrélés positivement.\n","\n","+ La corrélation est d'environ +0,45. Il existe une corrélation positive, mais elle est plutôt faible."],"metadata":{"id":"ps5R9aTyRITP"}},{"cell_type":"markdown","source":["####**Importer des données SPSS avec foreign (2)**\n","\n","\n","+ Dans l'exercice précédent, vous avez utilisé l'argument to.data.frame dans read.spss(). \n","\n","+ Il existe de nombreuses autres façons de personnaliser la manière dont vos données SPSS sont importées.\n","\n","+ Dans cet exercice, vous allez expérimenter avec un autre argument, use.value.labels. \n","\n","+ Il spécifie si les variables avec des étiquettes de valeur doivent être converties en facteurs R avec des niveaux qui sont nommés en conséquence. \n","\n","+ L'argument est TRUE par défaut, ce qui signifie que les variables étiquetées dans SPSS sont converties en facteurs dans R.\n","\n","+ Vous allez à nouveau travailler avec les données international.sav, qui sont disponibles dans votre répertoire de travail actuel.\n","\n","####**Instructions**\n","\n","+ Importez le fichier de données \"international.sav\" comme un cadre de données, demo_1.\n","\n","+ Imprimez les premières lignes de demo_1 en utilisant la fonction head().\n","\n","+ Importez le fichier de données \"international.sav\" en tant que cadre de données, demo_2, mais cette fois-ci de manière à ce que les variables avec des étiquettes de valeur ne soient pas converties en facteurs R.\n","\n","+ De nouveau, imprimez les premières lignes de demo_2. Pouvez-vous voir la différence entre les deux cadres de données ?"],"metadata":{"id":"ki16YkHFR15v"}},{"cell_type":"code","source":["# foreign is already loaded\n","\n","# Import international.sav as demo_1\n","demo_1 <- read.spss(\"international.sav\", to.data.frame = TRUE)\n","\n","# Print out the head of demo_1\n","head(demo_1)\n","\n","# Import international.sav as demo_2\n","demo_2 <- read.spss(\"international.sav\", to.data.frame = TRUE, use.value.labels = FALSE)\n","\n","# Print out the head of demo_2\n","head(demo_2)"],"metadata":{"id":"1XGAPSTSMg3g"},"execution_count":null,"outputs":[]}]}